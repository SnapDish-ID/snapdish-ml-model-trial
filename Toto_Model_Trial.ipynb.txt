{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Dataset**"
      ],
      "metadata": {
        "id": "FYQJkMGN6xFM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV1ONcXvs3OT",
        "outputId": "e21ae6f1-c62f-41c1-b7ba-d1977be81bea",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-24 07:48:52--  https://drive.google.com/uc?export=download&id=1XxuP8A3hKf2Nt6dtPny-j9w_cmcyRTSZ\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.115.100, 172.253.115.139, 172.253.115.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.115.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1XxuP8A3hKf2Nt6dtPny-j9w_cmcyRTSZ&export=download [following]\n",
            "--2024-11-24 07:48:52--  https://drive.usercontent.google.com/download?id=1XxuP8A3hKf2Nt6dtPny-j9w_cmcyRTSZ&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.179.132, 2607:f8b0:4004:c1f::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.179.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10092111 (9.6M) [application/octet-stream]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>]   9.62M  20.6MB/s    in 0.5s    \n",
            "\n",
            "2024-11-24 07:48:57 (20.6 MB/s) - ‘dataset.zip’ saved [10092111/10092111]\n",
            "\n",
            "Archive:  dataset.zip\n",
            "  inflating: dataset/Waluh/waluh4.jpg  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 094752.png  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 093848.png  \n",
            "  inflating: dataset/Waluh/waluh9.jpg  \n",
            "  inflating: dataset/Waluh/waluh3.jpg  \n",
            "  inflating: dataset/Waluh/waluh5.jpg  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 094911.png  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 093815.png  \n",
            "  inflating: dataset/Waluh/waluh13.jpg  \n",
            "  inflating: dataset/Waluh/waluh2.jpg  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 093921.png  \n",
            "  inflating: dataset/Waluh/waluh14.jpg  \n",
            "  inflating: dataset/Waluh/waluh7.jpg  \n",
            "  inflating: dataset/Waluh/waluh12.jpg  \n",
            "  inflating: dataset/Waluh/waluh11.jpg  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 093908.png  \n",
            "  inflating: dataset/Waluh/waluh15.jpg  \n",
            "  inflating: dataset/Waluh/waluh8.jpg  \n",
            "  inflating: dataset/Waluh/waluh6.jpg  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 093831.png  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 094147.png  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 094439.png  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 094045.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 102530.png  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 094246.png  \n",
            "  inflating: dataset/Waluh/waluh10.jpg  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 093757.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 194845.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 095616.png  \n",
            "  inflating: dataset/Waluh/waluh1.jpg  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 094539.png  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 093746.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 170329.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 102715.png  \n",
            "  inflating: dataset/Cabai Merah/Screenshot 2024-11-20 093729.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 194859.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 170758.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 170224.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 170249.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 101105.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 101021.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 095532.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 170256.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 101656.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 101241.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 101302.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 170829.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 170407.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 102255.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 101748.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 101228.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 101007.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 170807.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 170344.png  \n",
            "  inflating: dataset/Sosis/sosis8.jpg  \n",
            "  inflating: dataset/Sosis/sosis6.jpg  \n",
            "  inflating: dataset/Sosis/sosis9.jpg  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 170208.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 170305.png  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 195047.png  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 100955.png  \n",
            "  inflating: dataset/Sosis/sosis14.jpg  \n",
            "  inflating: dataset/Ayam/Screenshot 2024-11-20 194938.png  \n",
            "  inflating: dataset/Sosis/sosis7.jpg  \n",
            "  inflating: dataset/Sosis/sosis5.jpg  \n",
            "  inflating: dataset/Sosis/sosis1.jpg  \n",
            "  inflating: dataset/Sosis/sosis4.jpg  \n",
            "  inflating: dataset/Sosis/sosis2.jpg  \n",
            "  inflating: dataset/Bakso/bakso14.jpg  \n",
            "  inflating: dataset/Sosis/sosis15.jpg  \n",
            "  inflating: dataset/Bakso/bakso13.jpg  \n",
            "  inflating: dataset/Bakso/bakso11.jpg  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 101642.png  \n",
            "  inflating: dataset/Sosis/sosis3.jpg  \n",
            "  inflating: dataset/Sosis/sosis10.jpg  \n",
            "  inflating: dataset/Tahu/download (5).jpeg  \n",
            "  inflating: dataset/Sosis/sosis12.jpg  \n",
            "  inflating: dataset/Tahu/download (1).jpeg  \n",
            "  inflating: dataset/Bakso/bakso2.jpg  \n",
            "  inflating: dataset/Tahu/images (7).jpeg  \n",
            "  inflating: dataset/Tahu/download (2).jpeg  \n",
            "  inflating: dataset/Tahu/download (4).jpeg  \n",
            "  inflating: dataset/Bakso/bakso10.jpg  \n",
            "  inflating: dataset/Tahu/download (3).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot 2024-11-20 095242.png  \n",
            "  inflating: dataset/Sosis/sosis11.jpg  \n",
            "  inflating: dataset/Sosis/sosis13.jpg  \n",
            "  inflating: dataset/Bakso/bakso4.jpg  \n",
            "  inflating: dataset/Tahu/download (7).jpeg  \n",
            "  inflating: dataset/Bakso/bakso5.jpg  \n",
            "  inflating: dataset/Bakso/bakso15.jpg  \n",
            "  inflating: dataset/Bakso/bakso1.jpg  \n",
            "  inflating: dataset/Tempe/download (8).jpeg  \n",
            "  inflating: dataset/Tahu/images (5).jpeg  \n",
            "  inflating: dataset/Bakso/bakso12.jpg  \n",
            "  inflating: dataset/Tahu/images (4).jpeg  \n",
            "  inflating: dataset/Tahu/download (1).webp  \n",
            "  inflating: dataset/Tempe/download (13).jpeg  \n",
            "  inflating: dataset/Tempe/download (9).jpeg  \n",
            "  inflating: dataset/Tahu/download.jpeg  \n",
            "  inflating: dataset/Tahu/images (2).jpeg  \n",
            "  inflating: dataset/Bakso/bakso9.jpg  \n",
            "  inflating: dataset/Tempe/images (12).jpeg  \n",
            "  inflating: dataset/Bakso/bakso3.jpg  \n",
            "  inflating: dataset/Bakso/bakso7.jpg  \n",
            "  inflating: dataset/Bakso/bakso8.jpg  \n",
            "  inflating: dataset/Tempe/images (14).jpeg  \n",
            "  inflating: dataset/Tempe/images (10).jpeg  \n",
            "  inflating: dataset/Tempe/images (8).jpeg  \n",
            "  inflating: dataset/Tempe/images (11).jpeg  \n",
            "  inflating: dataset/Tempe/images (15).jpeg  \n",
            "  inflating: dataset/Tempe/images (9).jpeg  \n",
            "  inflating: dataset/Tempe/download (11).jpeg  \n",
            "  inflating: dataset/Tempe/images (13).jpeg  \n",
            "  inflating: dataset/Bakso/bakso6.jpg  \n",
            "  inflating: dataset/Tahu/images (3).jpeg  \n",
            "  inflating: dataset/Tahu/download (6).jpeg  \n",
            "  inflating: dataset/Tempe/download (12).jpeg  \n",
            "  inflating: dataset/Tahu/images (6).jpeg  \n",
            "  inflating: dataset/Tempe/images (16).jpeg  \n",
            "  inflating: dataset/Tempe/download (10).jpeg  \n"
          ]
        }
      ],
      "source": [
        "# !wget --no-check-certificate \"https://drive.google.com/uc?export=download&id=1XxuP8A3hKf2Nt6dtPny-j9w_cmcyRTSZ\" -O dataset.zip\n",
        "# !unzip dataset.zip -d dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d pradwitanasha/dataset-jpeg-trial-food-ingredients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbwuq5YOOINc",
        "outputId": "10edf73d-fc7c-4321-b95d-4e4e66774900"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/pradwitanasha/dataset-jpeg-trial-food-ingredients\n",
            "License(s): apache-2.0\n",
            "Downloading dataset-jpeg-trial-food-ingredients.zip to /content\n",
            " 81% 57.0M/70.2M [00:00<00:00, 146MB/s]\n",
            "100% 70.2M/70.2M [00:00<00:00, 151MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset-jpeg-trial-food-ingredients.zip -d dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RflqT-paPL4-",
        "outputId": "f237675a-d20c-4a38-da84-eedb0d2dcc45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset-jpeg-trial-food-ingredients.zip\n",
            "  inflating: dataset/Ayam/1136937_81968550-1b54-4908-a3e3-5ab4f1099926_1161_1161.jpeg  \n",
            "  inflating: dataset/Ayam/1167245_720.jpeg  \n",
            "  inflating: dataset/Ayam/18GPy1vDSG1Q.jpeg  \n",
            "  inflating: dataset/Ayam/201711281942253_b.jpeg  \n",
            "  inflating: dataset/Ayam/2022-01-08-jangan-pernah-cuci-ayam-mentah-sebelum-dimasak.jpeg  \n",
            "  inflating: dataset/Ayam/2690456462.jpeg  \n",
            "  inflating: dataset/Ayam/2884058488.jpeg  \n",
            "  inflating: dataset/Ayam/2e91101f90ada67e5c14dd9e210e9995.jpeg  \n",
            "  inflating: dataset/Ayam/31156333303-5-penyakit-yang-bisa-muncul-ketika-kita-makan-ayam-mentah-pzkgfdnpcu.jpeg  \n",
            "  inflating: dataset/Ayam/415e39c5-1927-42b5-ae6e-6134e4aa074e_169.jpeg  \n",
            "  inflating: dataset/Ayam/49761ab0-08b4-4b1c-92fb-9e33011c0664_169.jpeg  \n",
            "  inflating: dataset/Ayam/56e383c9-2316-46c4-929e-478a11d1b649.jpeg  \n",
            "  inflating: dataset/Ayam/57032bc6-f321-4e32-bb5a-219e54cdc6b1.jpeg  \n",
            "  inflating: dataset/Ayam/59905f4021cde763f60360f1bae5dea3-1024x723.jpeg  \n",
            "  inflating: dataset/Ayam/5d4932858115e-daging-ayam-mentah_1265_711.jpeg  \n",
            "  inflating: dataset/Ayam/62e5077b152a6jpg-20230801012424.jpeg  \n",
            "  inflating: dataset/Ayam/6329499bc24ff.jpeg  \n",
            "  inflating: dataset/Ayam/651f5dceee71djpg-20231119064824.jpeg  \n",
            "  inflating: dataset/Ayam/71995-ilustrasi-ayam-mentah-envato-elements-by-dream79.jpeg  \n",
            "  inflating: dataset/Ayam/752861303_3442a423-5cd0-409c-a3b5-3cb5e8926780_2048_2048.jpeg  \n",
            "  inflating: dataset/Ayam/8421997_a1fb9753-3fb6-4d15-b635-7293a90751f0_1125_1125.jpeg  \n",
            "  inflating: dataset/Ayam/9184_original_mencuci-ayam_20160327_105034.jpeg  \n",
            "  inflating: dataset/Ayam/Ayam-Mentah-4124531204.jpeg  \n",
            "  inflating: dataset/Ayam/Bahaya_Mencuci_Ayam_Potong_Mentah_.jpeg  \n",
            "  inflating: dataset/Ayam/Daging-ayam-Foto-Solid-Starts-P1673db6752920a4a.md.jpeg  \n",
            "  inflating: dataset/Ayam/Daging-ayam-dan-kebutuhan-pokok-lainnya-171058500.jpeg  \n",
            "  inflating: dataset/Ayam/Jangan-Mencuci-Daging-Ayam-Mentah--Beresiko-Fatal-untuk-Kesehatan-master-1853978032.jpeg  \n",
            "  inflating: dataset/Ayam/S3232d8a518ac4f96b66cbc286c64327bq.jpeg  \n",
            "  inflating: dataset/Ayam/SS.jpeg    \n",
            "  inflating: dataset/Ayam/Sebelum-Bahaya-Mengancam--Segera-Hentikan-Kebiasaan-Mencuci-Daging-Ayam-Mentah-master-1125725952.jpeg  \n",
            "  inflating: dataset/Ayam/WhatsApp-Image-2023-10-27-at-11.24.29.jpeg  \n",
            "  inflating: dataset/Ayam/appetite-1238525_1920.jpeg  \n",
            "  inflating: dataset/Ayam/ayam-1.jpeg  \n",
            "  inflating: dataset/Ayam/ayam-makanan-penambah-tinggi-badanfreepikcomtimolina.jpeg  \n",
            "  inflating: dataset/Ayam/ayam-mentah-1669344789151.jpeg  \n",
            "  inflating: dataset/Ayam/ayam-mentah-1669344822911.jpeg  \n",
            "  inflating: dataset/Ayam/ayam-mentah-1670335179085.jpeg  \n",
            "  inflating: dataset/Ayam/bakteri-salmonella-mengintai-hindari-konsumsi-ayam-mentah-atau-setengah-matang-sHRs6NzB9R.jpeg  \n",
            "  inflating: dataset/Ayam/berbahaya-jangan-cuci-daging-ayam-mentah.jpeg  \n",
            "  inflating: dataset/Ayam/brd-44261_kulit-ayam-mentah-bersih-segar-500-gram-freshmarketlampung_full01-f84dbc7f.jpeg  \n",
            "  inflating: dataset/Ayam/chicken-4761000_1280.jpeg  \n",
            "  inflating: dataset/Ayam/ciri-daging-ayam-tidak-layak-konsumsi-scaled.jpeg  \n",
            "  inflating: dataset/Ayam/d74ebe1a2404d3b782f9d9706618cea0.jpeg  \n",
            "  inflating: dataset/Ayam/daging-ayam-_170913174003-586.jpeg  \n",
            "  inflating: dataset/Ayam/daging-ayam-fillet-pixabay_169.jpeg  \n",
            "  inflating: dataset/Ayam/daging-ayam-mentah-1-e1625216138180.jpeg  \n",
            "  inflating: dataset/Ayam/daging-ayam-mentah-2-e1625216126633.jpeg  \n",
            "  inflating: dataset/Ayam/daging-ayam-mentah-e1709010199240.jpeg  \n",
            "  inflating: dataset/Ayam/daging-ayam-mentah.jpeg  \n",
            "  inflating: dataset/Ayam/daging-ayam-mentahfoto-freepikjcomp-1.jpeg  \n",
            "  inflating: dataset/Ayam/daging-ayam-yang-dijual-di-satu-kios-penjual-daging-ayam-di-pasar-tomang-barat.jpeg  \n",
            "  inflating: dataset/Ayam/daging-ayamjpg-20221118105820.jpeg  \n",
            "  inflating: dataset/Ayam/daging_ayam.jpeg  \n",
            "  inflating: dataset/Ayam/depositphotos_146161299-stock-photo-whole-raw-chicken.jpeg  \n",
            "  inflating: dataset/Ayam/depositphotos_38608453-stock-photo-raw-chicken-breast-fillets.jpeg  \n",
            "  inflating: dataset/Ayam/depositphotos_39791951-stock-photo-whole-raw-chicken.jpeg  \n",
            "  inflating: dataset/Ayam/download (1).jpeg  \n",
            "  inflating: dataset/Ayam/download (10).jpeg  \n",
            "  inflating: dataset/Ayam/download (11).jpeg  \n",
            "  inflating: dataset/Ayam/download (12).jpeg  \n",
            "  inflating: dataset/Ayam/download (13).jpeg  \n",
            "  inflating: dataset/Ayam/download (14).jpeg  \n",
            "  inflating: dataset/Ayam/download (15).jpeg  \n",
            "  inflating: dataset/Ayam/download (16).jpeg  \n",
            "  inflating: dataset/Ayam/download (17).jpeg  \n",
            "  inflating: dataset/Ayam/download (18).jpeg  \n",
            "  inflating: dataset/Ayam/download (19).jpeg  \n",
            "  inflating: dataset/Ayam/download (2).jpeg  \n",
            "  inflating: dataset/Ayam/download (20).jpeg  \n",
            "  inflating: dataset/Ayam/download (21).jpeg  \n",
            "  inflating: dataset/Ayam/download (3).jpeg  \n",
            "  inflating: dataset/Ayam/download (4).jpeg  \n",
            "  inflating: dataset/Ayam/download (5).jpeg  \n",
            "  inflating: dataset/Ayam/download (6).jpeg  \n",
            "  inflating: dataset/Ayam/download (7).jpeg  \n",
            "  inflating: dataset/Ayam/download (8).jpeg  \n",
            "  inflating: dataset/Ayam/download (9).jpeg  \n",
            "  inflating: dataset/Ayam/download.jpeg  \n",
            "  inflating: dataset/Ayam/jk-sloan-9zLa37VNL38-unsplash-1-998866310.jpeg  \n",
            "  inflating: dataset/Ayam/justbuy_usus_ayam_mentah_-frozen-_full01_rq9m2qzg.jpeg  \n",
            "  inflating: dataset/Ayam/makan-ayam-mentah.jpeg  \n",
            "  inflating: dataset/Ayam/meat-6054511_640.jpeg  \n",
            "  inflating: dataset/Ayam/no_brand_ayam_mentah_broiler_1_ekor_full04_hqmugjyn.jpeg  \n",
            "  inflating: dataset/Ayam/no_brand_usus_ayam_mentah_1_kg_fresh_full01_1100f1e2.jpeg  \n",
            "  inflating: dataset/Ayam/oQ5I3ISx81Pu.jpeg  \n",
            "  inflating: dataset/Ayam/paha-ayam-mentah-raw-chicken-260nw-2325283559.jpeg  \n",
            "  inflating: dataset/Ayam/pelanggan-dapat-ayam-mentah.jpeg  \n",
            "  inflating: dataset/Ayam/pexels-photo-5769376.jpeg  \n",
            "  inflating: dataset/Ayam/picsart-23-06-26-00-33-40-488-1758a0692afbc8274363a550b6365bae-7c2a244edc6b613b70542aaf3508322f_600x400.jpeg  \n",
            "  inflating: dataset/Ayam/pngtree-raw-chicken-chicken-legs-chicken-wings-fresh-png-image_6247994.jpeg  \n",
            "  inflating: dataset/Ayam/pngtree-raw-chicken-close-up-meal-chicken-breast-png-image_3226715.jpeg  \n",
            "  inflating: dataset/Ayam/proses-penyimpanan-ayam-di-kulkas-harus-dilakukan-dengan-baik_200508222619-106.jpeg  \n",
            "  inflating: dataset/Ayam/sfidn-penyakit-akibat-konsumsi-daging-ayam-mentah-873x585.jpeg  \n",
            "  inflating: dataset/Bakso/0_cc4c7cdf-c730-4876-83e2-2c460f00ddac_600_414.jpeg  \n",
            "  inflating: dataset/Bakso/1-11-1024x768.jpeg  \n",
            "  inflating: dataset/Bakso/1701396909.7483.jpeg  \n",
            "  inflating: dataset/Bakso/2-1081939863-Buka-Agen-Reseller-Supplier-Pentol-Bakso-Mentah-Kemasan-Yang-Enak.jpeg  \n",
            "  inflating: dataset/Bakso/270dbbd6-f46f-44e9-9d67-8cab55622b75.jpeg  \n",
            "  inflating: dataset/Bakso/35349634e7c906931476b98b85724b06.jpeg  \n",
            "  inflating: dataset/Bakso/3db04626-7785-4d47-8938-19f15a038f5c.jpeg  \n",
            "  inflating: dataset/Bakso/3e99cfd8346f322cb7e29be1950da153.jpeg  \n",
            "  inflating: dataset/Bakso/4419158_f8455a03-9756-44fa-8cb0-053a9babe1aa_796_796.jpeg  \n",
            "  inflating: dataset/Bakso/664xauto-buat-bakso-ayam-gurih-sendiri-simpel-banget-2208267.jpeg  \n",
            "  inflating: dataset/Bakso/71506c7b8c1c47b84a19204b37f659c2.jpeg  \n",
            "  inflating: dataset/Bakso/7198503_a3a3cbad-2809-4e97-aee0-4c373d1bc171_663_663.jpeg  \n",
            "  inflating: dataset/Bakso/8966400f0f483798d0617c931b3c4702.jpeg  \n",
            "  inflating: dataset/Bakso/9bce40dc-7651-4d2c-9013-c3b30aa2ccef.jpeg  \n",
            "  inflating: dataset/Bakso/9e753005-a693-4ede-9433-55705e2dc743.jpeg  \n",
            "  inflating: dataset/Bakso/Agen+Bakso+Sapi+1.jpeg  \n",
            "  inflating: dataset/Bakso/Bakso-Warisan-2.jpeg  \n",
            "  inflating: dataset/Bakso/Beef-meat-Ball.jpeg  \n",
            "  inflating: dataset/Bakso/KA82F32A1DC_brg21252.jpeg  \n",
            "  inflating: dataset/Bakso/KCCE83B62E7_brg18518.jpeg  \n",
            "  inflating: dataset/Bakso/S078ce663c8ad4faaad86dd1c4669e0b0C.jpeg  \n",
            "  inflating: dataset/Bakso/S90df3d80daee4b6bb33d34523a07c3812.jpeg  \n",
            "  inflating: dataset/Bakso/Sbe3a79384ab74cc2804948ec8a4c4302p.jpg_360x360q75.jpg_.jpeg  \n",
            "  inflating: dataset/Bakso/Sbe83443ac1434ee39ae82803b2531d96L.jpg_720x720q80.jpeg  \n",
            "  inflating: dataset/Bakso/agen-jual-bakso-sapi.jpeg  \n",
            "  inflating: dataset/Bakso/bakso-Sapi-1-1024x1024.jpeg  \n",
            "  inflating: dataset/Bakso/bakso-bulatjpg-20211216014802.jpeg  \n",
            "  inflating: dataset/Bakso/bakso-english-called-meatball-food-260nw-1831107637.jpeg  \n",
            "  inflating: dataset/Bakso/baso.jpeg  \n",
            "  inflating: dataset/Bakso/champion_champion_basreng_bakso_goreng_mentah_isi_25_butir_1kg_full02_ec223lst.jpeg  \n",
            "  inflating: dataset/Bakso/d1e124a1-2a1a-4a6e-bfda-6bc2f348ae6c.jpeg  \n",
            "  inflating: dataset/Bakso/data.jpeg  \n",
            "  inflating: dataset/Bakso/data.jpeg.jpeg  \n",
            "  inflating: dataset/Bakso/data.png.jpeg  \n",
            "  inflating: dataset/Bakso/depositphotos_113465200-stock-photo-rows-of-raw-homemade-meatballs.jpeg  \n",
            "  inflating: dataset/Bakso/depositphotos_140707754-stock-photo-raw-meatballs-with-pepper.jpeg  \n",
            "  inflating: dataset/Bakso/depositphotos_454285800-stock-photo-raw-home-made-italian-traditional.jpeg  \n",
            "  inflating: dataset/Bakso/download (1).jpeg  \n",
            "  inflating: dataset/Bakso/download (10).jpeg  \n",
            "  inflating: dataset/Bakso/download (11).jpeg  \n",
            "  inflating: dataset/Bakso/download (12).jpeg  \n",
            "  inflating: dataset/Bakso/download (13).jpeg  \n",
            "  inflating: dataset/Bakso/download (14).jpeg  \n",
            "  inflating: dataset/Bakso/download (15).jpeg  \n",
            "  inflating: dataset/Bakso/download (2).jpeg  \n",
            "  inflating: dataset/Bakso/download (3).jpeg  \n",
            "  inflating: dataset/Bakso/download (4).jpeg  \n",
            "  inflating: dataset/Bakso/download (5).jpeg  \n",
            "  inflating: dataset/Bakso/download (6).jpeg  \n",
            "  inflating: dataset/Bakso/download (7).jpeg  \n",
            "  inflating: dataset/Bakso/download (8).jpeg  \n",
            "  inflating: dataset/Bakso/download (9).jpeg  \n",
            "  inflating: dataset/Bakso/download.jpeg  \n",
            "  inflating: dataset/Bakso/e4345ff6-20e6-4665-9d72-d1244164ac38.jpeg  \n",
            "  inflating: dataset/Bakso/e6de8f0200e368699c0212f8a99a75ce.jpeg  \n",
            "  inflating: dataset/Bakso/ezeepasar_bakso_sapi_unyil_isi_50_pcs_full01_baj5blnl.jpeg  \n",
            "  inflating: dataset/Bakso/f3e8530a-6052-4b92-bfcc-e0c98a4e4761.jpeg  \n",
            "  inflating: dataset/Bakso/f7338beccfb84f63d27aa5b363ef9e92.jpg_960x960q80.jpg_.jpeg  \n",
            "  inflating: dataset/Bakso/id-11134207-7qukw-ljutnmapnj1eb7_tn.jpeg  \n",
            "  inflating: dataset/Bakso/id-11134207-7r98q-lq0q9ttfmdiw54_tn.jpeg  \n",
            "  inflating: dataset/Bakso/images (1).jpeg  \n",
            "  inflating: dataset/Bakso/images (2).jpeg  \n",
            "  inflating: dataset/Bakso/images (3).jpeg  \n",
            "  inflating: dataset/Bakso/images (4).jpeg  \n",
            "  inflating: dataset/Bakso/images.jpeg  \n",
            "  inflating: dataset/Bakso/jvGxZYtJZb0J.jpeg  \n",
            "  inflating: dataset/Bakso/lovepik-farmhouse-lean-meatballs-png-image_401509181_wh1200.jpeg  \n",
            "  inflating: dataset/Bakso/lovepik-meatball-png-image_400887148_wh1200.jpeg  \n",
            "  inflating: dataset/Bakso/meatballs-4682189_1280.jpeg  \n",
            "  inflating: dataset/Bakso/meatballs-6039656_640.jpeg  \n",
            "  inflating: dataset/Bakso/no-brand_bakso-baso-sapi-spesial_full01.jpeg  \n",
            "  inflating: dataset/Bakso/no_brand_baso_goreng_-basreng_mentah_cahaya_intan-_isi_25_pcs_full01_fea2eae0.jpeg  \n",
            "  inflating: dataset/Bakso/no_brand_baso_sapi_mentah_1kg_isi_25_full01_dv4hu4mi.jpeg  \n",
            "  inflating: dataset/Bakso/penjual-bakso-terdekat.jpeg  \n",
            "  inflating: dataset/Bakso/photo.jpeg  \n",
            "  inflating: dataset/Bakso/pngtree-meat-ball-chickpea-photo-png-image_14368156.jpeg  \n",
            "  inflating: dataset/Bakso/pngtree-meatballs-raw-main-dish-health-taste-png-image_12064371.jpeg  \n",
            "  inflating: dataset/Bakso/pngtree-raw-meatballs-close-up-on-wooden-raw-meatballs-bowl-pork-png-image_12081311.jpeg  \n",
            "  inflating: dataset/Bakso/pngtree-raw-meatballs-on-the-chopping-board-hash-hamburger-minced-meat-png-image_11795838.jpeg  \n",
            "  inflating: dataset/Bakso/pngtree-raw-meatballs-white-food-beef-png-image_11793702.jpeg  \n",
            "  inflating: dataset/Bakso/pngtree-raw-uncooked-meatballs-raw-meat-uncooked-ground-meat-photo-image_27813776.jpeg  \n",
            "  inflating: dataset/Bakso/r5wP7k84VcsM.jpeg  \n",
            "  inflating: dataset/Bakso/sg-11134201-7rd42-lvq7gdj3300z2e_tn.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/08a83f8cd70f95ba00bbb935d56e7f69.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/0a80fe420eeed7efc9f79f7439061d24.jpg_720x720q80.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/10-manfaat-sehat-makan-cabai-hijau-bisa-tingkatkan-imunitas-3.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/1200x600-ini-dia-14-manfaat-cabai-hijau-untuk-kesehatan-tak-banyak-yang-tahu-190923h.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/1200xauto-tanpa-ditambah-jeruk-nipis-ini-trik-bikin-sambal-cabai-hijau-agar-warnanya-tak-menghitam-2306057.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/1200xauto-trik-agar-sambal-cabai-hijau-tidak-pucat-dan-warnanya-tetap-segar-220923h.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/132517-182845aceb39c9e413e28fd549058cf8-132517 (1).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/132517-182845aceb39c9e413e28fd549058cf8-132517.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/13_07_2022_05_12_49_cabe_merah_besar.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/140ba653-0a26-4f2e-8716-f841d877b39c.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/15_07_2022_01_49_12_cabe_hijau_besarr.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/1698805379-picsay.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/1866975-resep-olahan-ikan-cabai-ijo.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/1_A8169530002065_20240816101255959_base.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/23b9949159513c4760d4eb02fcea161e.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/2682101997.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/27821-resep-daging-cabai-hijau-ala-chef-devina-hermawan.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/47c62408-5e15-4899-9e8d-2350a68f6b29.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/5-Tips-Pilih-Cabe-Hijau-untuk-Bahan-Sambal-Ijo.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/5-rahasia-cabai-hijau-untuk-kesehatan-termasuk-cegah-kanker_m_.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/5r9xpnh5f4zdav2 (1).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/5r9xpnh5f4zdav2.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/6304ce7c2001861f4c7d0068_Cabe_Rawit_Hijau-thumbnail-540x540.png  \n",
            "  inflating: dataset/Cabai Hijau/6942468_df65d591-1d1d-4957-9228-b2afe19c5367_640_640.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/7175728_5f4f7846-748a-45ef-9923-1c1d19934791_1000_1000.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/76f8126d9334130b22d4f4beca5bb06c.png_720x720q80.png  \n",
            "  inflating: dataset/Cabai Hijau/7793791_c4719406-4cac-4f43-844b-3cc25b78e2d9_1560_1560.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/8d0ed3e8-bcff-4125-a7e5-9b51030ca51a.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/AbVddo8lAT0X.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/CABE-RAWIT-HIJAU-100-GR-GRADE-B-_1_d6afbfe0-d0e5-4350-b608-872a13822bfb-removebg-preview.png  \n",
            "  inflating: dataset/Cabai Hijau/CABEHIJAUBESAR500G2-removebg-preview.png  \n",
            "  inflating: dataset/Cabai Hijau/Cabai-Hijau.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/Cabe-Hijau-Besar.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/Cabe-Hijau.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/Cara-masak-cabe-hijau-agar-warnanya-tetap-hijau.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/Resep-Daging-Cabai-Hijau-yang-Enak-dan-Mudah-Dibuat-Cocok-untuk-Pemula-1981436850.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/S89bfb9bc6cae4c9385196586637e105dS.jpg_720x720q80.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/Screenshot_20231216-105418_Instagram-3480461077.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/Tumis-Cabai-Hijau.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/a6esumxnqjkc431.png  \n",
            "  inflating: dataset/Cabai Hijau/ase-cabai-hijau-keriting-ala-kampung-foto-resep-utama.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/ayam-cabe-hijau-1.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/ayam-penyet-cabe-ijo-aa-sipit-viral-di-grand-indonesia-4_169.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/brd-44261_cabe-hijau-besar-100-gr-cabai-tanjung-chili-rempah-masakan-fresh_full01.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/bum-002IB_750x.png  \n",
            "  inflating: dataset/Cabai Hijau/c810157d-07ac-4e7e-9a85-c8f3e94789a2.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/cabai-hijau (1).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/cabai-hijau (2).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/cabai-hijau-_171004143108-996.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/cabai-hijau-ampuh-cerahkan-kulit-7FOA78vPvE.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/cabai-hijau-besar.png  \n",
            "  inflating: dataset/Cabai Hijau/cabai_rawit_hijau.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/cabaijpg-20210914055618.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/cabaijpg-20230115120919.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/cabe-keriting-hijau-1-SESA_1-removebg-preview.png  \n",
            "  inflating: dataset/Cabai Hijau/cabe1.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/cabehbesar_580x.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/cabehijau_1200x1200.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (1).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (10).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (11).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (12).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (13).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (14).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (15).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (16).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (17).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (18).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (19).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (2).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (20).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (21).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (22).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (23).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (3).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (4).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (5).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (6).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (7).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (8).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download (9).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/download.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/fe0fa5f2-a1a6-4e49-a6ef-f2769b7239e2-article-1586091067 (1).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/fe0fa5f2-a1a6-4e49-a6ef-f2769b7239e2-article-1586091067.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/hb.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/hq720.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/iwjcsw5nztcp5ep.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/jangan-takut-pedas-ini-10-manfaat-makan-cabai-hijau-bagi-kesehatan-Wa9o4cyzLu.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/kedaisayur_cabe_rawit_hijau_500_gram-kedaimart_full01_c16de52t.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/maxresdefault (1).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/maxresdefault.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/no_brand_cabe_-_cabai_hijau_besar_petik_segar_1_kg_full01_h6pz8dhq.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/no_brands_cabe_cabai_hijau_besar_full03_mazgxgtg.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/png-transparent-green-chili-pepper.png  \n",
            "  inflating: dataset/Cabai Hijau/pngtree-fresh-green-chili-on-png-background-png-image_2629076.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/pngtree-green-chili-png-image_4355616.png  \n",
            "  inflating: dataset/Cabai Hijau/produk_1537342967.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/resep-oseng-ikan-sepat-cabe-hijau-1_43 (1).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/resep-oseng-ikan-sepat-cabe-hijau-1_43.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/resep-sambal-leunca-cabe-hijau_43 (1).jpeg  \n",
            "  inflating: dataset/Cabai Hijau/resep-sambal-leunca-cabe-hijau_43.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/rsz_cara_menyimpan_cabai_hijauj-20221216023916.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/three-hit-chili-peppers-white-ba-20220403120218.jpeg  \n",
            "  inflating: dataset/Cabai Hijau/tidak_ada_merk_cabe_hijau_keriting_segar_1kg_cabai_fresh_1_kg_full01_6b5a4c02.jpeg  \n",
            "  inflating: dataset/Cabai Merah/00ae9d7b-6950-4784-bd0c-8c0a43518183.jpeg  \n",
            "  inflating: dataset/Cabai Merah/09915b62-3fcd-4246-b7d5-576d262be47d.jpeg  \n",
            "  inflating: dataset/Cabai Merah/1000009212.jpeg  \n",
            "  inflating: dataset/Cabai Merah/1304505334.jpeg  \n",
            "  inflating: dataset/Cabai Merah/2.jpeg  \n",
            "  inflating: dataset/Cabai Merah/20160527Harga-Cabai-Merah-Naik-270516-Pf-2.jpeg  \n",
            "  inflating: dataset/Cabai Merah/20231102-20221208-img20221208123354.jpeg  \n",
            "  inflating: dataset/Cabai Merah/20240308_-_Deputi_Bapanas_ungkap_Alasan_Kenaikan_Harga_Cabai_Merah_Besar_di_Pasaran.jpeg  \n",
            "  inflating: dataset/Cabai Merah/20240324-cabai-nora.jpeg  \n",
            "  inflating: dataset/Cabai Merah/20241004-img-20241003-114038.jpeg  \n",
            "  inflating: dataset/Cabai Merah/21_07_2022_05_19_30_cabe_merah_besar_kg.jpeg  \n",
            "  inflating: dataset/Cabai Merah/47219446534-cabe.jpeg  \n",
            "  inflating: dataset/Cabai Merah/4741_cabe.jpeg  \n",
            "  inflating: dataset/Cabai Merah/4vj3tjyswxhwg3u.jpeg  \n",
            "  inflating: dataset/Cabai Merah/53NBzv7r3ML42pxWGrWLn9hP7luyappz3ppDBzsm.jpeg  \n",
            "  inflating: dataset/Cabai Merah/609faf35be344.jpeg  \n",
            "  inflating: dataset/Cabai Merah/6318679f3fd8c_20220907164255-1.jpeg  \n",
            "  inflating: dataset/Cabai Merah/863285.jpeg  \n",
            "  inflating: dataset/Cabai Merah/Cabai-Dery-Ridwansah-4.jpeg  \n",
            "  inflating: dataset/Cabai Merah/Cabai-Merah-Bahan-Masakan-yang-Dicintai-Warga-Indonesia.jpeg  \n",
            "  inflating: dataset/Cabai Merah/Cabai-merah-besar-di-HST-berubah-signifikan.jpeg  \n",
            "  inflating: dataset/Cabai Merah/CabeRawitMerahOrganik200GR.jpeg  \n",
            "  inflating: dataset/Cabai Merah/Chilipeber.jpeg  \n",
            "  inflating: dataset/Cabai Merah/Foto-oleh-The-Sport-Review.jpeg  \n",
            "  inflating: dataset/Cabai Merah/Harga-cabai-merah-naik.jpeg  \n",
            "  inflating: dataset/Cabai Merah/IMG-20220126-WA0007_1280x.jpeg  \n",
            "  inflating: dataset/Cabai Merah/IMG_20231101_014216.jpeg  \n",
            "  inflating: dataset/Cabai Merah/MENJAGA-MUTU-CABAI-MERAH-DENGAN-PANEN-YANG-BAIK-DAN-BENAR-366x400.jpeg  \n",
            "  inflating: dataset/Cabai Merah/Mengenal-Manfaat-Cabai-Merah-Bagi-Kesehatan.jpeg  \n",
            "  inflating: dataset/Cabai Merah/ay9zalrmxoep8ov.jpeg  \n",
            "  inflating: dataset/Cabai Merah/brc-2013660000000-1.jpeg  \n",
            "  inflating: dataset/Cabai Merah/brd-44261_tanaman-buah-cabai-merah-besar-cabe-merah-besar_full01.jpeg  \n",
            "  inflating: dataset/Cabai Merah/c7bcecab529ba4a1967d4a06357517a6.jpeg  \n",
            "  inflating: dataset/Cabai Merah/cabai-mb.jpeg  \n",
            "  inflating: dataset/Cabai Merah/cabai-merah (1).jpeg  \n",
            "  inflating: dataset/Cabai Merah/cabai-merah (2).jpeg  \n",
            "  inflating: dataset/Cabai Merah/cabai-merah.jpeg  \n",
            "  inflating: dataset/Cabai Merah/cabai_merah.jpeg  \n",
            "  inflating: dataset/Cabai Merah/cabai_merah_kramat_jati.jpeg  \n",
            "  inflating: dataset/Cabai Merah/cabai_produksi.jpeg  \n",
            "  inflating: dataset/Cabai Merah/cabaijpg-20230115120919.jpeg  \n",
            "  inflating: dataset/Cabai Merah/cabe-cabai-merah-keriting-red-600nw-2427609949.jpeg  \n",
            "  inflating: dataset/Cabai Merah/cara_budidaya_cabe.jpeg  \n",
            "  inflating: dataset/Cabai Merah/cayenne-peppers-2779828_1280.jpeg  \n",
            "  inflating: dataset/Cabai Merah/chilli-pepper-dark-surface.jpeg  \n",
            "  inflating: dataset/Cabai Merah/cmk_580x.jpeg  \n",
            "  inflating: dataset/Cabai Merah/d8d94c5b2ce5d4a83600a9d4101c4f.jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (1).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (10).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (11).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (12).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (13).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (14).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (15).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (16).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (17).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (18).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (2).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (3).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (4).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (5).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (6).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (7).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (8).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download (9).jpeg  \n",
            "  inflating: dataset/Cabai Merah/download.jpeg  \n",
            "  inflating: dataset/Cabai Merah/dunia_sayur_online_cabe_merah_keriting_100_gram_full01_h75ztglj.jpeg  \n",
            "  inflating: dataset/Cabai Merah/f6c77d68f0748e1c5f11973439b9a2f6.jpeg  \n",
            "  inflating: dataset/Cabai Merah/f804ff_0d7ba5a7b69d498d8399edc972e0d482mv2.jpeg  \n",
            "  inflating: dataset/Cabai Merah/fe0fa5f2-a1a6-4e49-a6ef-f2769b7239e2-article-1586091067.jpeg  \n",
            "  inflating: dataset/Cabai Merah/freshbox_cabai-merah-keriting-sayuran--250-g-_full07.jpeg  \n",
            "  inflating: dataset/Cabai Merah/harga-cabai-masih-menjadi-komoditas-yang-mengalami-kenaikan-pada-jumat-112-harga-cabai-merah-dan-cabe-rawit-telah-mengalami-ke-10_169.jpeg  \n",
            "  inflating: dataset/Cabai Merah/harga-cabai-merah-di-pasar-senapela.jpeg  \n",
            "  inflating: dataset/Cabai Merah/harga-cabai-merah-keriting-di-pasar-kramat-jati-turun-3_169.jpeg  \n",
            "  inflating: dataset/Cabai Merah/harga-cabai-merah-tingkat-petani-turun-di-aceh-13o4x-dom-copy.jpeg  \n",
            "  inflating: dataset/Cabai Merah/harga-cabai-rawit-makin-pedas-jelang-idul-adha-tembus-rp-50-ribu-per-kg-4_169.jpeg  \n",
            "  inflating: dataset/Cabai Merah/harga-cabe-semakin-pedas-7_169.jpeg  \n",
            "  inflating: dataset/Cabai Merah/harga_cabai_merah_di_pasar_tradisional_kota_medan.jpeg  \n",
            "  inflating: dataset/Cabai Merah/hq720.jpeg  \n",
            "  inflating: dataset/Cabai Merah/image-20231201150242.jpeg  \n",
            "  inflating: dataset/Cabai Merah/images.jpeg  \n",
            "  inflating: dataset/Cabai Merah/longchili_530x@2x.jpeg  \n",
            "  inflating: dataset/Cabai Merah/news_68716_1480668953.jpeg  \n",
            "  inflating: dataset/Cabai Merah/oem_cabe_merah_besar_-_cabai_merah_besar_segar_1_kg_full01_qodan37r.jpeg  \n",
            "  inflating: dataset/Cabai Merah/pedagang-memotong-cabai-merah-keritinh-yang-dijual-di-kawasan-pasar-pondok-gede-jakarta-rabu-2962022-cnbc-indonesiamuhammad-sa-9_169.jpeg  \n",
            "  inflating: dataset/Cabai Merah/pngtree-red-pepper-png-image_5617132.jpeg  \n",
            "  inflating: dataset/Cabai Merah/tak-hanya-pedas-banyak-manfaat-cabai-untuk-kesehatan-tubuh.jpeg  \n",
            "  inflating: dataset/Cabai Merah/top-view-red-chili-peppers-600nw-2489224461.jpeg  \n",
            "  inflating: dataset/Sosis/022723a9-f443-4a49-9ded-5dc11fe743cc.jpeg  \n",
            "  inflating: dataset/Sosis/124b5834-ee89-459b-b24f-09439dcfa940.jpeg  \n",
            "  inflating: dataset/Sosis/2019-09-13-10-39-02.jpeg  \n",
            "  inflating: dataset/Sosis/23027a0e-1eaf-432f-a9cd-0b0b13af2759.jpeg  \n",
            "  inflating: dataset/Sosis/3439659_b00eb195-d177-47b8-b62a-333374374f0b_700_700.jpeg  \n",
            "  inflating: dataset/Sosis/7432194_b1dd9d03-be7e-49f7-8e49-6afb737ad15a_1224_1224.jpeg  \n",
            "  inflating: dataset/Sosis/BEmMfUfaLcjl.jpeg  \n",
            "  inflating: dataset/Sosis/Kenali-Karakteristik-pada-Produk-Sosis-yang-Bagus.jpeg  \n",
            "  inflating: dataset/Sosis/Plastic-Casing-for-Raw-Sausage-Cooked-Sausage.jpeg  \n",
            "  inflating: dataset/Sosis/S4f956818fc2b42a3885c74271310c2b3H.jpg_360x360q75.jpg_.jpeg  \n",
            "  inflating: dataset/Sosis/Saf27ee3db28b45aca407776a9ad4d073Y.jpeg  \n",
            "  inflating: dataset/Sosis/Sd19cd91435104461b7c832e82c3d578a4.jpg_360x360q75.jpg_.jpeg  \n",
            "  inflating: dataset/Sosis/YewoHeJ6Fg.jpeg  \n",
            "  inflating: dataset/Sosis/c38a8c90-7b49-47f2-8220-371c23dd3ae9.jpeg  \n",
            "  inflating: dataset/Sosis/d9333-sosis-bakar-jumbo.jpeg  \n",
            "  inflating: dataset/Sosis/depositphotos_110000718-stock-photo-raw-sausages-for-grill.jpeg  \n",
            "  inflating: dataset/Sosis/depositphotos_13866045-stock-photo-raw-sausage-and-ingredient.jpeg  \n",
            "  inflating: dataset/Sosis/depositphotos_13940133-stock-photo-isolated-raw-sausage.jpeg  \n",
            "  inflating: dataset/Sosis/depositphotos_38491121-stock-photo-sausage-on.jpeg  \n",
            "  inflating: dataset/Sosis/depositphotos_44011387-stock-photo-raw-sausage.jpeg  \n",
            "  inflating: dataset/Sosis/depositphotos_445101280-stock-photo-raw-meat-sausages-isolated-white.jpeg  \n",
            "  inflating: dataset/Sosis/depositphotos_45516641-stock-photo-raw-sausages.jpeg  \n",
            "  inflating: dataset/Sosis/depositphotos_46147619-stock-photo-raw-sausages.jpeg  \n",
            "  inflating: dataset/Sosis/depositphotos_647278330-stock-photo-one-fresh-raw-sausage-isolated.jpeg  \n",
            "  inflating: dataset/Sosis/depositphotos_70391545-stock-photo-raw-sausages-on-white-background.jpeg  \n",
            "  inflating: dataset/Sosis/depositphotos_8368710-stock-photo-isolated-raw-sausage-and-parsley.jpeg  \n",
            "  inflating: dataset/Sosis/download (1).jpeg  \n",
            "  inflating: dataset/Sosis/download (10).jpeg  \n",
            "  inflating: dataset/Sosis/download (11).jpeg  \n",
            "  inflating: dataset/Sosis/download (12).jpeg  \n",
            "  inflating: dataset/Sosis/download (13).jpeg  \n",
            "  inflating: dataset/Sosis/download (14).jpeg  \n",
            "  inflating: dataset/Sosis/download (15).jpeg  \n",
            "  inflating: dataset/Sosis/download (16).jpeg  \n",
            "  inflating: dataset/Sosis/download (17).jpeg  \n",
            "  inflating: dataset/Sosis/download (18).jpeg  \n",
            "  inflating: dataset/Sosis/download (19).jpeg  \n",
            "  inflating: dataset/Sosis/download (2).jpeg  \n",
            "  inflating: dataset/Sosis/download (20).jpeg  \n",
            "  inflating: dataset/Sosis/download (21).jpeg  \n",
            "  inflating: dataset/Sosis/download (3).jpeg  \n",
            "  inflating: dataset/Sosis/download (4).jpeg  \n",
            "  inflating: dataset/Sosis/download (5).jpeg  \n",
            "  inflating: dataset/Sosis/download (6).jpeg  \n",
            "  inflating: dataset/Sosis/download (7).jpeg  \n",
            "  inflating: dataset/Sosis/download (8).jpeg  \n",
            "  inflating: dataset/Sosis/download (9).jpeg  \n",
            "  inflating: dataset/Sosis/download.jpeg  \n",
            "  inflating: dataset/Sosis/edb174b5e8244c22f43be349622c7d18.jpg_360x360q75.jpg_.jpeg  \n",
            "  inflating: dataset/Sosis/mettwurst-6166303_1280.jpeg  \n",
            "  inflating: dataset/Sosis/oem_lapciong-lapchiong-sosis-babi-medan-enakkkk-500g_full01.jpeg  \n",
            "  inflating: dataset/Sosis/png-clipart-sausage-hot-dog-stuffing-turkey-casing-attractive-ham-food-chicken-meat.jpeg  \n",
            "  inflating: dataset/Sosis/png-clipart-uncooked-sausage-platter-pack-of-thin-beef-sausages-food-sausages.jpeg  \n",
            "  inflating: dataset/Sosis/png-transparent-bratwurst-sausage-ham-salami-frankfurter-wurstchen-luncheon-meat-food-chicken-meat-raw-meat.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-3d-a-stack-of-raw-sausages-on-white-ceramic-plate-png-image_13114287.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-3d-raw-sausages-with-tomatoes-for-barbecue-png-image_13336441.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-artfully-arranged-ingredients-and-raw-sausages-on-a-white-textured-tray-image_13645170.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-pile-of-sausages-chain-raw-food-photo-picture-image_8236866.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-raw-sausages-isolated-on-white-background-beef-lunch-bbq-photo-image_33079708.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-raw-short-sausages-sausages-top-view-wurst-photo-image_24113876.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-uncooked-frankfurter-sausages-arranged-on-a-wooden-kitchen-table-shot-from-above-photo-image_40235864.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-variety-of-fresh-raw-sausages-made-from-pork-beef-and-chicken-displayed-on-a-black-background-photo-image_35031276.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-vienna-sausages-casing-uncooked-sausages-photo-image_22665944.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-vienna-sausages-chicken-sausage-salted-raw-photo-picture-image_8637189.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-vienna-sausages-chicken-sausages-raw-frankfurter-photo-image_23317646.jpeg  \n",
            "  inflating: dataset/Sosis/pngtree-vienna-sausages-raw-uncooked-chicken-sausages-photo-picture-image_8778934.jpeg  \n",
            "  inflating: dataset/Sosis/salsiccia4-e1469526616688-f04373ca9428bde3dcc199a92bb6fc6e.jpeg  \n",
            "  inflating: dataset/Sosis/sausage-556491_1280.jpeg  \n",
            "  inflating: dataset/Sosis/sausage-6922637_1280.jpeg  \n",
            "  inflating: dataset/Sosis/sausagescover.jpeg  \n",
            "  inflating: dataset/Sosis/so-eco_sosis-so-eco_full01.jpeg  \n",
            "  inflating: dataset/Sosis/sosis-kemasanjpg-20231220115018.jpeg  \n",
            "  inflating: dataset/Sosis/sosis-youtube.jpeg  \n",
            "  inflating: dataset/Sosis/stock-photo-raw-sausage-240594745.jpeg  \n",
            "  inflating: dataset/Sosis/the-sausage-891510_640.jpeg  \n",
            "  inflating: dataset/Sosis/vigo_sosis_vigo_sosis_vigo_ayam_900gr_isi_40_full01_ntxw0a3z.jpeg  \n",
            "  inflating: dataset/Tahu/051513477f781162ef38f8ba4baaa17c.jpeg  \n",
            "  inflating: dataset/Tahu/0eeadb0b-a32d-48ce-ba42-e0b59159fe33_menu-item-image_1625037248660.jpeg  \n",
            "  inflating: dataset/Tahu/12-manfaat-tahu-mentah-yang-nggak-disangka-sangka-rugi-lho-kalau-jijik-duluan-sebelum-mencobanya-200226z.jpeg  \n",
            "  inflating: dataset/Tahu/1428f3ab-10b6-400e-827d-5a654fb5abd4.jpeg  \n",
            "  inflating: dataset/Tahu/1665734972-5dfc2aa9541dd4058c4ebf47.jpeg  \n",
            "  inflating: dataset/Tahu/1721187thumb-IMG-4965-1024780x390.jpeg  \n",
            "  inflating: dataset/Tahu/2062996887.jpeg  \n",
            "  inflating: dataset/Tahu/2454501031.jpeg  \n",
            "  inflating: dataset/Tahu/276d7e0e-9da9-4b9a-a5fd-781ed98e072a_169.jpeg  \n",
            "  inflating: dataset/Tahu/28873263252-img_20210103_084105.jpeg  \n",
            "  inflating: dataset/Tahu/2ea848f77ca8f597be7f48112b3882.png  \n",
            "  inflating: dataset/Tahu/32771269-27d7-4a68-ac2f-ed96d9c5459b.jpeg  \n",
            "  inflating: dataset/Tahu/49d8223a-9729-43f2-98df-515a3def49ab.jpeg  \n",
            "  inflating: dataset/Tahu/5-efek-samping-makan-tahu-terhadap-kesehatan-5CEgbFQi9o.jpeg  \n",
            "  inflating: dataset/Tahu/5805385_d6a668ad-bef2-49e8-9828-3b340aaf4fd6_620_620.jpeg  \n",
            "  inflating: dataset/Tahu/5fca23a2-7a6e-4269-8030-ca21fc89e0aa_Go-Biz_20210802_234854 (1).jpeg  \n",
            "  inflating: dataset/Tahu/5fca23a2-7a6e-4269-8030-ca21fc89e0aa_Go-Biz_20210802_234854.jpeg  \n",
            "  inflating: dataset/Tahu/Berbahaya-Bagi-Kesehatan-Tubuh--Jangan-Lagi-Mengkonsumsi-Tahu-Mentah--master-1997819319.jpeg  \n",
            "  inflating: dataset/Tahu/Manfaat-Makan-Tahu-Mentah-dan-Risiko-yang-Perlu-Diketahui.jpeg  \n",
            "  inflating: dataset/Tahu/Nlo74ITYrv1M.jpeg  \n",
            "  inflating: dataset/Tahu/S181d0cb5bb5448a38f820f6b3c83bc79l.jpeg  \n",
            "  inflating: dataset/Tahu/S3e71a25e52f042c398e803f14cc6e4a8n.jpg_720x720q80.jpeg  \n",
            "  inflating: dataset/Tahu/S76ad2ad0515c4915b4d89a9247b2a700B.jpg_720x720q80.jpeg  \n",
            "  inflating: dataset/Tahu/Sbdcf7fa20f1b4990b42f8e4b3e37f8abx.jpg_720x720q80.jpeg  \n",
            "  inflating: dataset/Tahu/Ternyata-Mengkonsumsi-Tahu-Mentah-Berbahaya-Bagi-Kesehatan-Tubuh-master-1399708411.jpeg  \n",
            "  inflating: dataset/Tahu/Towang-Tahu-Kuning-250-Gr-_2_43501b07-f6c1-464c-ac6b-74589ac17640-removebg-preview.png  \n",
            "  inflating: dataset/Tahu/U9AE17L4AO33PSAE.jpeg  \n",
            "  inflating: dataset/Tahu/ZdUfVAUUGYmO.jpeg  \n",
            "  inflating: dataset/Tahu/begini-cara-menyimpan-tahu-agar-tidak-asam-dan-lebih-awet.jpeg  \n",
            "  inflating: dataset/Tahu/brd-44261_tahu-putih-kuning-mentah-segar-1-plastik-freshmarketlampung_full01-f3b1f69f.jpeg  \n",
            "  inflating: dataset/Tahu/cb312d05-208d-44cc-8c8e-6d7a4f6775be.jpeg  \n",
            "  inflating: dataset/Tahu/depositphotos_489554216-stock-photo-blocks-delicious-raw-tofu-basil.jpeg  \n",
            "  inflating: dataset/Tahu/download (1).jpeg  \n",
            "  inflating: dataset/Tahu/download (10).jpeg  \n",
            "  inflating: dataset/Tahu/download (11).jpeg  \n",
            "  inflating: dataset/Tahu/download (12).jpeg  \n",
            "  inflating: dataset/Tahu/download (13).jpeg  \n",
            "  inflating: dataset/Tahu/download (14).jpeg  \n",
            "  inflating: dataset/Tahu/download (15).jpeg  \n",
            "  inflating: dataset/Tahu/download (16).jpeg  \n",
            "  inflating: dataset/Tahu/download (17).jpeg  \n",
            "  inflating: dataset/Tahu/download (2).jpeg  \n",
            "  inflating: dataset/Tahu/download (3).jpeg  \n",
            "  inflating: dataset/Tahu/download (4).jpeg  \n",
            "  inflating: dataset/Tahu/download (5).jpeg  \n",
            "  inflating: dataset/Tahu/download (6).jpeg  \n",
            "  inflating: dataset/Tahu/download (7).jpeg  \n",
            "  inflating: dataset/Tahu/download (8).jpeg  \n",
            "  inflating: dataset/Tahu/download (9).jpeg  \n",
            "  inflating: dataset/Tahu/download.jpeg  \n",
            "  inflating: dataset/Tahu/downloadfile.jpeg  \n",
            "  inflating: dataset/Tahu/fe9436fc-74f1-4773-8159-552a5d679174.jpeg  \n",
            "  inflating: dataset/Tahu/hq720.jpeg  \n",
            "  inflating: dataset/Tahu/iVUS5Od9ZeMy.jpeg  \n",
            "  inflating: dataset/Tahu/ilustrasi-menyimpan-tahu-dalam-larutan-air-garam-untuk-menjaganya-lebih-tahan-lama.jpeg  \n",
            "  inflating: dataset/Tahu/ionJZqOPWYJt.jpeg  \n",
            "  inflating: dataset/Tahu/kerupuk-tahu.jpeg  \n",
            "  inflating: dataset/Tahu/manfaat-tahu-1024x512.jpeg  \n",
            "  inflating: dataset/Tahu/manfaat-tahu-dan-resep-sehat-olahannya.jpeg  \n",
            "  inflating: dataset/Tahu/maxresdefault.jpeg  \n",
            "  inflating: dataset/Tahu/no-brand_tahu-kuning-mentah-5-pcs_full01.jpeg  \n",
            "  inflating: dataset/Tahu/no-brand_tahu-mentah-bandung-500gram-isi-5-biji_full01.jpeg  \n",
            "  inflating: dataset/Tahu/no-brand_tahu-pong-mentah-per-pcs-tahu-gehu_full01.jpeg  \n",
            "  inflating: dataset/Tahu/no-brand_tahu-putih-mentah-3-pcs_full01.jpeg  \n",
            "  inflating: dataset/Tahu/no-brand_tahu-sumedang-mentah-pcs_full01.jpeg  \n",
            "  inflating: dataset/Tahu/photo (1).jpeg  \n",
            "  inflating: dataset/Tahu/photo.jpeg  \n",
            "  inflating: dataset/Tahu/pngtree-cubes-of-raw-tofu-on-transparent-background-png-image_13053532.png  \n",
            "  inflating: dataset/Tahu/pngtree-stacked-raw-tofu-with-sparkle-vector-png-image_12279032.png  \n",
            "  inflating: dataset/Tahu/raw-tofu-on-wooden-cutting-260nw-2247657743.jpeg  \n",
            "  inflating: dataset/Tahu/stock-photo-tahu-putih-or-tofu-one-of-raw-ingredient-food-made-from-fermented-soybean-extract-served-in-tosca-2009851967.jpeg  \n",
            "  inflating: dataset/Tahu/t_5eb67b1de39f3.jpeg  \n",
            "  inflating: dataset/Tahu/tahu-goreng-sambal-mentah-foto-resep-utama.jpeg  \n",
            "  inflating: dataset/Tahu/tahu-mentah-santan-kuning-pedas-foto-resep-utama.jpeg  \n",
            "  inflating: dataset/Tahu/tahu-putih_20160329_122556.jpeg  \n",
            "  inflating: dataset/Tahu/tahu-sumedang-satu-rasa-Layanan-fiks.jpeg  \n",
            "  inflating: dataset/Tahu/tahu-sutra.jpeg  \n",
            "  inflating: dataset/Tahu/tahu-takwa.jpeg  \n",
            "  inflating: dataset/Tahu/tempe-dan-tahu-hilang-di-pasaran-ini-faktanya-1_169.jpeg  \n",
            "  inflating: dataset/Tahu/tofu-4081697_1280jpg-20210905040619.jpeg  \n",
            "  inflating: dataset/Tempe/1200xauto-cara-membuat-tempe-mentah-enak-sederhana-dan-mudah-dibuat-200812a.jpeg  \n",
            "  inflating: dataset/Tempe/1287446-cara-membuat-tempe-mentah.jpeg  \n",
            "  inflating: dataset/Tempe/12d6d7f1-3fe6-414b-827a-8ce043b9a173.jpeg  \n",
            "  inflating: dataset/Tempe/20210328044433Tempe_Mentah_olahan.jpeg  \n",
            "  inflating: dataset/Tempe/2021090304203053ef07f7-1f4e-495e-965d-3d19b049bc6c_crop_74.jpeg  \n",
            "  inflating: dataset/Tempe/2435158120.jpeg  \n",
            "  inflating: dataset/Tempe/280d34c4ae1e4c8cc9456070e89a33af.jpeg  \n",
            "  inflating: dataset/Tempe/289A745B_9252_4EDF_AED5_F2AA6F8A2A43 (1).jpeg  \n",
            "  inflating: dataset/Tempe/289A745B_9252_4EDF_AED5_F2AA6F8A2A43.jpeg  \n",
            "  inflating: dataset/Tempe/2abfb3d1596f882c9a8a98b1edb80c.jpeg  \n",
            "  inflating: dataset/Tempe/559b295d3c23090a6ea04c9a6fa4a7b0.jpeg  \n",
            "  inflating: dataset/Tempe/600e2adfce9b1-tempe_1265_711.jpeg  \n",
            "  inflating: dataset/Tempe/62c3e1e52f9e2-manfaat-tempe.jpeg  \n",
            "  inflating: dataset/Tempe/65b8954e9c567-tahukah-anda-kalau-makan-tempe-lebih-baik-yang-mentah_1265_711.jpeg  \n",
            "  inflating: dataset/Tempe/91688891826-tempe_dan_kurma.jpeg  \n",
            "  inflating: dataset/Tempe/9ebb6df9ad550b1a43bfbb4ef6e2e193.jpeg  \n",
            "  inflating: dataset/Tempe/Manfaat-Tempe-Mentah-Bagi-Kesehatan-676377421.jpeg  \n",
            "  inflating: dataset/Tempe/Screenshot_20240924-201658_Chrome-3686494172.jpeg  \n",
            "  inflating: dataset/Tempe/Tempe-Mentah (2).jpeg  \n",
            "  inflating: dataset/Tempe/Tempe-Mentah.jpeg  \n",
            "  inflating: dataset/Tempe/a0fa18ef-5d73-4366-b605-e2aae18dbf81.jpeg  \n",
            "  inflating: dataset/Tempe/a51csn5erk6038t.jpeg  \n",
            "  inflating: dataset/Tempe/b4872520-bb1c-4775-b0fb-77edbbc74bc9.jpeg  \n",
            "  inflating: dataset/Tempe/bG9jYWw6Ly8vcHVibGlzaGVycy8xNDExODgvMjAyMzExMTAxNjI4LW1haW4uY3JvcHBlZF8xNjk5NjA4NTIwLmpwZw.jpeg  \n",
            "  inflating: dataset/Tempe/bb610e61-54af-48c7-ad33-2626adb7208e.jpeg  \n",
            "  inflating: dataset/Tempe/bc05d9165951fbeee1cc7a2f71ed919b.jpg_720x720q80.jpeg  \n",
            "  inflating: dataset/Tempe/brd-44261_tempe-mentah-segar-fresh-berkualitas-1-kotak_full01-d6c5a6a7.jpeg  \n",
            "  inflating: dataset/Tempe/c15ulb5m1c8eua4 (1).jpeg  \n",
            "  inflating: dataset/Tempe/c15ulb5m1c8eua4.jpeg  \n",
            "  inflating: dataset/Tempe/cca449950771af995a7522fa64df59f1.jpg_720x720q80.jpeg  \n",
            "  inflating: dataset/Tempe/d50ee03f-4e3e-4ae4-a564-9f1df55acbcb.jpeg  \n",
            "  inflating: dataset/Tempe/d78481098839737b09d6df8773537494.jpeg  \n",
            "  inflating: dataset/Tempe/depositphotos_6739322-stock-photo-tempeh.jpeg  \n",
            "  inflating: dataset/Tempe/desain-tanpajnp5ttfwyp1woduh.jpeg  \n",
            "  inflating: dataset/Tempe/download (1).jpeg  \n",
            "  inflating: dataset/Tempe/download (10).jpeg  \n",
            "  inflating: dataset/Tempe/download (11).jpeg  \n",
            "  inflating: dataset/Tempe/download (12).jpeg  \n",
            "  inflating: dataset/Tempe/download (13).jpeg  \n",
            "  inflating: dataset/Tempe/download (14).jpeg  \n",
            "  inflating: dataset/Tempe/download (15).jpeg  \n",
            "  inflating: dataset/Tempe/download (16).jpeg  \n",
            "  inflating: dataset/Tempe/download (17).jpeg  \n",
            "  inflating: dataset/Tempe/download (18).jpeg  \n",
            "  inflating: dataset/Tempe/download (19).jpeg  \n",
            "  inflating: dataset/Tempe/download (2).jpeg  \n",
            "  inflating: dataset/Tempe/download (3).jpeg  \n",
            "  inflating: dataset/Tempe/download (4).jpeg  \n",
            "  inflating: dataset/Tempe/download (5).jpeg  \n",
            "  inflating: dataset/Tempe/download (6).jpeg  \n",
            "  inflating: dataset/Tempe/download (7).jpeg  \n",
            "  inflating: dataset/Tempe/download (8).jpeg  \n",
            "  inflating: dataset/Tempe/download (9).jpeg  \n",
            "  inflating: dataset/Tempe/download.jpeg  \n",
            "  inflating: dataset/Tempe/ezgifcom-gif-maker-2023-11-11-20231111111411.jpeg  \n",
            "  inflating: dataset/Tempe/f9a95f78743f18eab9e633b113ceffd0.jpeg  \n",
            "  inflating: dataset/Tempe/ilustrasi-tempe-1.jpeg  \n",
            "  inflating: dataset/Tempe/ilustrasi-tempe-mentah-1_169.jpeg  \n",
            "  inflating: dataset/Tempe/ilustrasi-tempe-mentah.jpeg  \n",
            "  inflating: dataset/Tempe/ilustrasi-tempe-mentah_169.jpeg  \n",
            "  inflating: dataset/Tempe/image_750x_635fc5ee71c3d.jpeg  \n",
            "  inflating: dataset/Tempe/image_750x_64df50d86bfa9.jpeg  \n",
            "  inflating: dataset/Tempe/image_870x_647fec58da6f5.jpeg  \n",
            "  inflating: dataset/Tempe/img-20220525-wa0000-628fc6b553e2c333e522d162.jpeg  \n",
            "  inflating: dataset/Tempe/jose-2023-09-21T171730.013.jpeg  \n",
            "  inflating: dataset/Tempe/manfaat-tempe.jpeg  \n",
            "  inflating: dataset/Tempe/mario-2023-09-21T171645.154.jpeg  \n",
            "  inflating: dataset/Tempe/mini-retort-tempe-mentah.jpeg  \n",
            "  inflating: dataset/Tempe/no-brand_tempe-mentah-jumbo_full01.jpeg  \n",
            "  inflating: dataset/Tempe/pngtree-free-download-raw-tempe-png-image_8664543.png  \n",
            "  inflating: dataset/Tempe/pngtree-tempe-panjang-illustrations-png-image-png-image_6554105.jpeg  \n",
            "  inflating: dataset/Tempe/raw-tempe-tempe-mentah-makanan-full-enzim-probiotik-foto-resep-utama.jpeg  \n",
            "  inflating: dataset/Tempe/rsz_tempe-5553223_1280-3684215698.jpeg  \n",
            "  inflating: dataset/Tempe/sddefault.jpeg  \n",
            "  inflating: dataset/Tempe/sliced-triangle-raw-tempeh-tempe-20230302023355.jpeg  \n",
            "  inflating: dataset/Tempe/stock-photo-raw-tempeh-or-tempe-mentah-bulat-tempeh-slices-in-wooden-plate-raw-soybean-seeds-in-a-brown-2037503906.jpeg  \n",
            "  inflating: dataset/Tempe/stock-photo-raw-tempeh-or-tempe-mentah-bulat-tempeh-slices-in-wooden-plate-raw-soybean-seeds-in-a-brown-2037503930.jpeg  \n",
            "  inflating: dataset/Tempe/tempe (1).jpeg  \n",
            "  inflating: dataset/Tempe/tempe-3.jpeg  \n",
            "  inflating: dataset/Tempe/tempe-mentah (1).jpeg  \n",
            "  inflating: dataset/Tempe/tempe-mentah-doktersehat.jpeg  \n",
            "  inflating: dataset/Tempe/tempe-mentah-foto-resep-utama.jpeg  \n",
            "  inflating: dataset/Tempe/tempe-mentah-raw-tempeh-uncooked-260nw-2267605551.jpeg  \n",
            "  inflating: dataset/Tempe/tempe-mentah_596819-290.jpeg  \n",
            "  inflating: dataset/Tempe/tempe.jpeg  \n",
            "  inflating: dataset/Tempe/tempeh-indonesian-traditional-food-made-from-fermented-soybeans_431906-308.jpeg  \n",
            "  inflating: dataset/Tempe/vr9737ghi3z7dff.jpeg  \n",
            "  inflating: dataset/Tempe/z2f273scae52c78 (1).jpeg  \n",
            "  inflating: dataset/Tempe/z2f273scae52c78.jpeg  \n",
            "  inflating: dataset/Waluh/0_15db2965-f823-4354-b10b-4f1f2c9478b8_1280_720.jpeg  \n",
            "  inflating: dataset/Waluh/14099774121413212831.jpeg  \n",
            "  inflating: dataset/Waluh/155603307735042_c22e6272-ae1b-41ff-8d6c-952650bb5ced.jpeg  \n",
            "  inflating: dataset/Waluh/1960822f92cdeab1a0a30c0a97d0ab28.jpeg  \n",
            "  inflating: dataset/Waluh/1d990411cc0016fd8774f73db547f320.jpeg  \n",
            "  inflating: dataset/Waluh/1fa9f560-b10d-481a-873b-70cd9f1e65b8.jpeg  \n",
            "  inflating: dataset/Waluh/20130107pumpkins.jpeg  \n",
            "  inflating: dataset/Waluh/20200905_203502.jpeg  \n",
            "  inflating: dataset/Waluh/23-bubur-waluh-2153110893.jpeg  \n",
            "  inflating: dataset/Waluh/250px-Waluh.jpeg  \n",
            "  inflating: dataset/Waluh/3032004866.jpeg  \n",
            "  inflating: dataset/Waluh/461273243_1580455899522005_6667348653879165442_n.jpeg  \n",
            "  inflating: dataset/Waluh/64ccaaeb208d9-waluh-kukus.jpeg  \n",
            "  inflating: dataset/Waluh/64ccaafea9776-waluh-kukus.jpeg  \n",
            "  inflating: dataset/Waluh/64ccab1164b89-waluh-kukus.jpeg  \n",
            "  inflating: dataset/Waluh/748755171.jpeg  \n",
            "  inflating: dataset/Waluh/81b0271a8c32286398ac58711f01d811.jpeg  \n",
            "  inflating: dataset/Waluh/853c898634b3c77af353fc309a897b5d.jpg_720x720q80.jpeg  \n",
            "  inflating: dataset/Waluh/88b9232d-f7d2-43db-8fa7-2c8430ec19ad.jpeg  \n",
            "  inflating: dataset/Waluh/91959fe8-35c8-4605-93f6-7b3d72e3caa0.jpeg  \n",
            "  inflating: dataset/Waluh/Cucurbita_2019_G1.jpeg  \n",
            "  inflating: dataset/Waluh/IMG_20210823_161736.jpeg  \n",
            "  inflating: dataset/Waluh/IMG_20210823_161900.jpeg  \n",
            "  inflating: dataset/Waluh/Panen-Waluh.jpeg  \n",
            "  inflating: dataset/Waluh/Pumpkins.jpeg  \n",
            "  inflating: dataset/Waluh/Red-Lampion.jpeg  \n",
            "  inflating: dataset/Waluh/Sbe3723c389b340d3905895332089a550M.jpg_720x720q80.jpeg  \n",
            "  inflating: dataset/Waluh/TAbWNH4F20230329100851.jpg.jpeg  \n",
            "  inflating: dataset/Waluh/Waluh-labu-parang-labu-kuning.jpeg  \n",
            "  inflating: dataset/Waluh/buah-waluh-terberat-6n77-dom.jpeg  \n",
            "  inflating: dataset/Waluh/camilan_Waluh.jpeg  \n",
            "  inflating: dataset/Waluh/download (1).jpeg  \n",
            "  inflating: dataset/Waluh/download (10).jpeg  \n",
            "  inflating: dataset/Waluh/download (12).jpeg  \n",
            "  inflating: dataset/Waluh/download (13).jpeg  \n",
            "  inflating: dataset/Waluh/download (14).jpeg  \n",
            "  inflating: dataset/Waluh/download (15).jpeg  \n",
            "  inflating: dataset/Waluh/download (16).jpeg  \n",
            "  inflating: dataset/Waluh/download (17).jpeg  \n",
            "  inflating: dataset/Waluh/download (19).jpeg  \n",
            "  inflating: dataset/Waluh/download (2).jpeg  \n",
            "  inflating: dataset/Waluh/download (20).jpeg  \n",
            "  inflating: dataset/Waluh/download (3).jpeg  \n",
            "  inflating: dataset/Waluh/download (4).jpeg  \n",
            "  inflating: dataset/Waluh/download (5).jpeg  \n",
            "  inflating: dataset/Waluh/download (6).jpeg  \n",
            "  inflating: dataset/Waluh/download (7).jpeg  \n",
            "  inflating: dataset/Waluh/download (8).jpeg  \n",
            "  inflating: dataset/Waluh/download (9).jpeg  \n",
            "  inflating: dataset/Waluh/download.jpeg  \n",
            "  inflating: dataset/Waluh/eed56e80251137e99d21cadbf0fa1ceb.jpg_720x720q80.jpeg  \n",
            "  inflating: dataset/Waluh/f078f27765f0bd57819be246b739e2b1.jpeg  \n",
            "  inflating: dataset/Waluh/img-20230607-194430-64807bd708a8b566725601f2.jpeg  \n",
            "  inflating: dataset/Waluh/maxresdefault.jpeg  \n",
            "  inflating: dataset/Waluh/news_75386_1496472446.jpeg  \n",
            "  inflating: dataset/Waluh/no-brand_labu-kuning-waluh-sayur-labu-sayur-labu-kuning-buah-labu-kuning_full01.jpeg  \n",
            "  inflating: dataset/Waluh/no_brand_labu_kuning_-_waluh_-_walo_happyfruits_-_1buah_full01_jo80a69g.jpeg  \n",
            "  inflating: dataset/Waluh/pexels-jacqueline-smith-5704350-3241d69518fb4418eb841c3d4dc24ca6-dc36a0e842cb082ad8deb0f3eea20bcb_600x400.jpeg  \n",
            "  inflating: dataset/Waluh/potensi_44035.20.14.20105f4f0a1d348989.19536452.jpeg  \n",
            "  inflating: dataset/Waluh/potensi_4405f4f0a27b462f3.84782797.jpeg  \n",
            "  inflating: dataset/Waluh/waluh-juai-2014.jpeg  \n",
            "  inflating: dataset/Waluh/waluh.jpeg  \n",
            "  inflating: dataset/Waluh/waluh1.jpeg  \n",
            "  inflating: dataset/Waluh/waluh10.jpeg  \n",
            "  inflating: dataset/Waluh/waluh11.jpeg  \n",
            "  inflating: dataset/Waluh/waluh12.jpeg  \n",
            "  inflating: dataset/Waluh/waluh13.jpeg  \n",
            "  inflating: dataset/Waluh/waluh14.jpeg  \n",
            "  inflating: dataset/Waluh/waluh15.jpeg  \n",
            "  inflating: dataset/Waluh/waluh2.jpeg  \n",
            "  inflating: dataset/Waluh/waluh3.jpeg  \n",
            "  inflating: dataset/Waluh/waluh4.jpeg  \n",
            "  inflating: dataset/Waluh/waluh5.jpeg  \n",
            "  inflating: dataset/Waluh/waluh6.jpeg  \n",
            "  inflating: dataset/Waluh/waluh7.jpeg  \n",
            "  inflating: dataset/Waluh/waluh8.jpeg  \n",
            "  inflating: dataset/Waluh/waluh9.jpeg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Dir = './dataset'"
      ],
      "metadata": {
        "id": "AGt50Hux3XTN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sU25gNjwVc8R",
        "outputId": "c11a7118-02bd-4799-8d0e-99214e29997a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.36-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.36-py3-none-any.whl (887 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.3/887.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.36 ultralytics-thop-2.0.12\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n.pt')  # Replace 'yolov8n.pt' with your desired model"
      ],
      "metadata": {
        "id": "d7V1tB2cVoeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f74d6e-8cab-4065-8389-8c3c559df7e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 75.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Library**"
      ],
      "metadata": {
        "id": "jfMxFF2969ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Wpq9T2Mi2XoA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Train Val Dataset**"
      ],
      "metadata": {
        "id": "z60R6Guq7N6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_datasets():\n",
        "\n",
        "    training_dataset, validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        directory=Data_Dir,\n",
        "        image_size=(120,120),\n",
        "        batch_size=10,\n",
        "        validation_split=0.2,\n",
        "        subset=\"both\",\n",
        "        seed=42\n",
        "    )\n",
        "    return training_dataset, validation_dataset"
      ],
      "metadata": {
        "id": "9Fu8-llK5GkE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset, validation_dataset = train_val_datasets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAWHbxhc7wOG",
        "outputId": "feff3297-7849-4e98-f40a-02a6ddb2b707"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 690 files belonging to 8 classes.\n",
            "Using 552 files for training.\n",
            "Using 138 files for validation.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import numpy as np # Make sure numpy is imported\n",
        "import cv2\n",
        "\n",
        "def train_val_datasets():\n",
        "    training_dataset, validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        directory=Data_Dir,  # Make sure Data_Dir is correctly defined\n",
        "        image_size=(150,150),\n",
        "        batch_size=10,\n",
        "        validation_split=0.2,\n",
        "        subset=\"both\",\n",
        "        seed=42\n",
        "    )\n",
        "    return training_dataset, validation_dataset\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO(\"yolov8n.pt\")  # or your desired model path\n",
        "\n",
        "# Get the training and validation datasets\n",
        "training_dataset, validation_dataset = train_val_datasets()\n",
        "\n",
        "# Iterate through the training dataset and make predictions\n",
        "for images, labels in training_dataset:\n",
        "    # Convert the TensorFlow tensor to a NumPy array and ensure it's in the correct format\n",
        "    images_np = images.numpy()\n",
        "\n",
        "    # Iterate over each image in the batch\n",
        "    for img in images_np:\n",
        "        # Convert the image to uint8 (expected by OpenCV)\n",
        "        img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Perform inference on individual images\n",
        "        results = model(img)\n",
        "        # Process the results, e.g., display them or store them\n",
        "        for result in results:\n",
        "            result.save()  # Or result.print(), result.save(), etc.\n",
        "\n",
        "# Similarly, iterate through the validation dataset\n",
        "for images, labels in validation_dataset:\n",
        "    # Convert the TensorFlow tensor to a NumPy array and ensure it's in the correct format\n",
        "    images_np = images.numpy()\n",
        "\n",
        "    # Iterate over each image in the batch\n",
        "    for img in images_np:\n",
        "        # Convert the image to uint8 (expected by OpenCV)\n",
        "        img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Perform inference on individual images\n",
        "        results = model(img)\n",
        "        # Process the results\n",
        "        for result in results:\n",
        "            result.save()  # Or result.print(), result.save(), etc."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "i3dqMdzfX0yJ",
        "outputId": "54e95df2-e0f5-4d50-b684-e235b1f74d45"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 690 files belonging to 8 classes.\n",
            "Using 552 files for training.\n",
            "Using 138 files for validation.\n",
            "\n",
            "0: 640x640 1 vase, 369.4ms\n",
            "Speed: 6.9ms preprocess, 369.4ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 broccoli, 383.2ms\n",
            "Speed: 5.1ms preprocess, 383.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 350.8ms\n",
            "Speed: 4.4ms preprocess, 350.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 donuts, 354.5ms\n",
            "Speed: 4.2ms preprocess, 354.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 cake, 373.1ms\n",
            "Speed: 4.6ms preprocess, 373.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 oranges, 373.3ms\n",
            "Speed: 4.6ms preprocess, 373.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 395.3ms\n",
            "Speed: 4.4ms preprocess, 395.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 2 broccolis, 367.2ms\n",
            "Speed: 4.1ms preprocess, 367.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 279.6ms\n",
            "Speed: 4.3ms preprocess, 279.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 237.6ms\n",
            "Speed: 4.1ms preprocess, 237.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 247.6ms\n",
            "Speed: 9.9ms preprocess, 247.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 hot dogs, 227.9ms\n",
            "Speed: 4.3ms preprocess, 227.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 232.4ms\n",
            "Speed: 4.2ms preprocess, 232.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 bowls, 1 orange, 1 donut, 243.1ms\n",
            "Speed: 3.5ms preprocess, 243.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 246.5ms\n",
            "Speed: 3.9ms preprocess, 246.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 247.5ms\n",
            "Speed: 4.0ms preprocess, 247.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 carrots, 233.8ms\n",
            "Speed: 4.2ms preprocess, 233.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 241.4ms\n",
            "Speed: 4.3ms preprocess, 241.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kite, 245.5ms\n",
            "Speed: 4.3ms preprocess, 245.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 227.1ms\n",
            "Speed: 4.5ms preprocess, 227.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 243.6ms\n",
            "Speed: 8.8ms preprocess, 243.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 fire hydrant, 244.7ms\n",
            "Speed: 5.5ms preprocess, 244.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 240.1ms\n",
            "Speed: 4.9ms preprocess, 240.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 orange, 237.9ms\n",
            "Speed: 4.6ms preprocess, 237.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 251.2ms\n",
            "Speed: 4.7ms preprocess, 251.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bed, 232.6ms\n",
            "Speed: 3.9ms preprocess, 232.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.0ms\n",
            "Speed: 4.0ms preprocess, 245.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 235.0ms\n",
            "Speed: 4.7ms preprocess, 235.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 242.4ms\n",
            "Speed: 5.8ms preprocess, 242.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 239.1ms\n",
            "Speed: 5.2ms preprocess, 239.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.1ms\n",
            "Speed: 5.0ms preprocess, 245.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 traffic lights, 238.1ms\n",
            "Speed: 4.6ms preprocess, 238.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 vase, 250.0ms\n",
            "Speed: 4.1ms preprocess, 250.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 241.1ms\n",
            "Speed: 5.6ms preprocess, 241.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 carrots, 242.7ms\n",
            "Speed: 4.5ms preprocess, 242.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 235.3ms\n",
            "Speed: 5.1ms preprocess, 235.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 243.5ms\n",
            "Speed: 4.2ms preprocess, 243.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 236.7ms\n",
            "Speed: 4.9ms preprocess, 236.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.6ms\n",
            "Speed: 4.8ms preprocess, 245.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 233.3ms\n",
            "Speed: 4.0ms preprocess, 233.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 284.6ms\n",
            "Speed: 4.2ms preprocess, 284.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 236.3ms\n",
            "Speed: 4.3ms preprocess, 236.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 238.2ms\n",
            "Speed: 4.0ms preprocess, 238.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 hot dogs, 234.3ms\n",
            "Speed: 4.1ms preprocess, 234.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 251.8ms\n",
            "Speed: 4.5ms preprocess, 251.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 227.5ms\n",
            "Speed: 4.8ms preprocess, 227.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 237.6ms\n",
            "Speed: 4.1ms preprocess, 237.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 341.7ms\n",
            "Speed: 5.8ms preprocess, 341.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 357.6ms\n",
            "Speed: 4.1ms preprocess, 357.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 359.1ms\n",
            "Speed: 4.2ms preprocess, 359.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 oranges, 358.0ms\n",
            "Speed: 4.3ms preprocess, 358.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 orange, 351.7ms\n",
            "Speed: 4.0ms preprocess, 351.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 364.7ms\n",
            "Speed: 4.3ms preprocess, 364.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cat, 362.6ms\n",
            "Speed: 5.5ms preprocess, 362.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 oranges, 1 donut, 391.9ms\n",
            "Speed: 7.3ms preprocess, 391.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 399.4ms\n",
            "Speed: 4.2ms preprocess, 399.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 340.7ms\n",
            "Speed: 4.1ms preprocess, 340.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 227.8ms\n",
            "Speed: 4.2ms preprocess, 227.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 sandwich, 257.2ms\n",
            "Speed: 4.2ms preprocess, 257.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 pizzas, 1 dining table, 229.2ms\n",
            "Speed: 4.0ms preprocess, 229.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 238.4ms\n",
            "Speed: 5.6ms preprocess, 238.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 223.0ms\n",
            "Speed: 4.8ms preprocess, 223.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sheep, 264.0ms\n",
            "Speed: 5.0ms preprocess, 264.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 242.8ms\n",
            "Speed: 4.1ms preprocess, 242.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 232.5ms\n",
            "Speed: 4.9ms preprocess, 232.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 238.2ms\n",
            "Speed: 4.4ms preprocess, 238.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 broccoli, 248.6ms\n",
            "Speed: 4.7ms preprocess, 248.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 225.7ms\n",
            "Speed: 4.5ms preprocess, 225.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 potted plant, 234.3ms\n",
            "Speed: 5.2ms preprocess, 234.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 222.7ms\n",
            "Speed: 4.1ms preprocess, 222.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 278.4ms\n",
            "Speed: 4.8ms preprocess, 278.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 234.6ms\n",
            "Speed: 5.1ms preprocess, 234.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 bananas, 2 donuts, 233.4ms\n",
            "Speed: 4.9ms preprocess, 233.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 carrot, 228.1ms\n",
            "Speed: 5.1ms preprocess, 228.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 2 hot dogs, 262.6ms\n",
            "Speed: 5.0ms preprocess, 262.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 1 dining table, 244.5ms\n",
            "Speed: 4.8ms preprocess, 244.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 236.4ms\n",
            "Speed: 4.6ms preprocess, 236.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 229.7ms\n",
            "Speed: 4.4ms preprocess, 229.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 260.9ms\n",
            "Speed: 4.6ms preprocess, 260.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 cakes, 235.3ms\n",
            "Speed: 4.3ms preprocess, 235.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 237.9ms\n",
            "Speed: 4.3ms preprocess, 237.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 231.8ms\n",
            "Speed: 4.0ms preprocess, 231.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 257.0ms\n",
            "Speed: 4.2ms preprocess, 257.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 bananas, 6 donuts, 233.9ms\n",
            "Speed: 4.2ms preprocess, 233.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 234.0ms\n",
            "Speed: 4.7ms preprocess, 234.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 232.5ms\n",
            "Speed: 4.8ms preprocess, 232.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 251.9ms\n",
            "Speed: 4.2ms preprocess, 251.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 oranges, 3 carrots, 232.4ms\n",
            "Speed: 4.3ms preprocess, 232.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 cake, 223.7ms\n",
            "Speed: 5.0ms preprocess, 223.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 231.7ms\n",
            "Speed: 4.6ms preprocess, 231.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 263.5ms\n",
            "Speed: 4.3ms preprocess, 263.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 237.6ms\n",
            "Speed: 5.1ms preprocess, 237.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 225.8ms\n",
            "Speed: 4.9ms preprocess, 225.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 236.1ms\n",
            "Speed: 4.0ms preprocess, 236.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 knife, 1 scissors, 251.6ms\n",
            "Speed: 5.6ms preprocess, 251.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 233.5ms\n",
            "Speed: 4.7ms preprocess, 233.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 2 carrots, 5 hot dogs, 1 donut, 356.3ms\n",
            "Speed: 4.1ms preprocess, 356.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bird, 405.6ms\n",
            "Speed: 4.0ms preprocess, 405.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 15 donuts, 345.2ms\n",
            "Speed: 4.0ms preprocess, 345.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 broccoli, 373.8ms\n",
            "Speed: 4.4ms preprocess, 373.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 374.9ms\n",
            "Speed: 4.2ms preprocess, 374.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 368.0ms\n",
            "Speed: 4.0ms preprocess, 368.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 donuts, 1 teddy bear, 420.5ms\n",
            "Speed: 4.2ms preprocess, 420.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 1 cake, 379.6ms\n",
            "Speed: 4.8ms preprocess, 379.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 bananas, 249.4ms\n",
            "Speed: 4.2ms preprocess, 249.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 giraffe, 235.6ms\n",
            "Speed: 4.3ms preprocess, 235.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 244.0ms\n",
            "Speed: 4.4ms preprocess, 244.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 teddy bear, 228.2ms\n",
            "Speed: 4.8ms preprocess, 228.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 birds, 229.9ms\n",
            "Speed: 5.2ms preprocess, 229.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bottle, 244.8ms\n",
            "Speed: 4.4ms preprocess, 244.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 1 vase, 285.1ms\n",
            "Speed: 8.6ms preprocess, 285.1ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 potted plant, 229.4ms\n",
            "Speed: 4.9ms preprocess, 229.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.1ms\n",
            "Speed: 4.7ms preprocess, 245.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 vase, 224.6ms\n",
            "Speed: 4.2ms preprocess, 224.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bottle, 245.0ms\n",
            "Speed: 4.4ms preprocess, 245.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bird, 227.9ms\n",
            "Speed: 4.1ms preprocess, 227.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 245.1ms\n",
            "Speed: 4.8ms preprocess, 245.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 229.8ms\n",
            "Speed: 4.0ms preprocess, 229.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 hot dog, 1 cake, 1 dining table, 247.0ms\n",
            "Speed: 5.2ms preprocess, 247.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 222.7ms\n",
            "Speed: 4.9ms preprocess, 222.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 239.1ms\n",
            "Speed: 5.6ms preprocess, 239.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cup, 2 donuts, 2 cakes, 230.1ms\n",
            "Speed: 3.9ms preprocess, 230.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 cakes, 234.7ms\n",
            "Speed: 4.1ms preprocess, 234.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 carrots, 2 toothbrushs, 234.0ms\n",
            "Speed: 4.1ms preprocess, 234.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 clock, 253.2ms\n",
            "Speed: 4.1ms preprocess, 253.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 4 carrots, 227.2ms\n",
            "Speed: 4.1ms preprocess, 227.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 240.8ms\n",
            "Speed: 5.1ms preprocess, 240.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 bananas, 227.3ms\n",
            "Speed: 4.2ms preprocess, 227.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 237.9ms\n",
            "Speed: 4.5ms preprocess, 237.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 3 sandwichs, 225.5ms\n",
            "Speed: 4.1ms preprocess, 225.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 broccolis, 241.0ms\n",
            "Speed: 6.0ms preprocess, 241.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 230.1ms\n",
            "Speed: 4.0ms preprocess, 230.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 247.3ms\n",
            "Speed: 5.1ms preprocess, 247.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 237.6ms\n",
            "Speed: 4.1ms preprocess, 237.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 7 donuts, 250.7ms\n",
            "Speed: 4.0ms preprocess, 250.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 229.2ms\n",
            "Speed: 4.0ms preprocess, 229.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 243.5ms\n",
            "Speed: 4.1ms preprocess, 243.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 knife, 1 dining table, 231.4ms\n",
            "Speed: 4.3ms preprocess, 231.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 1 hot dog, 248.1ms\n",
            "Speed: 4.2ms preprocess, 248.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 233.0ms\n",
            "Speed: 4.4ms preprocess, 233.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 262.6ms\n",
            "Speed: 4.3ms preprocess, 262.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 239.0ms\n",
            "Speed: 4.0ms preprocess, 239.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 carrots, 236.2ms\n",
            "Speed: 4.0ms preprocess, 236.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 310.8ms\n",
            "Speed: 4.2ms preprocess, 310.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 dog, 358.6ms\n",
            "Speed: 4.3ms preprocess, 358.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 357.4ms\n",
            "Speed: 3.9ms preprocess, 357.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 358.8ms\n",
            "Speed: 4.2ms preprocess, 358.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 dog, 1 wine glass, 2 bowls, 358.7ms\n",
            "Speed: 4.1ms preprocess, 358.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 359.3ms\n",
            "Speed: 4.1ms preprocess, 359.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 fork, 1 bowl, 1 dining table, 366.6ms\n",
            "Speed: 4.0ms preprocess, 366.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 402.2ms\n",
            "Speed: 12.7ms preprocess, 402.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 carrots, 392.8ms\n",
            "Speed: 4.9ms preprocess, 392.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 339.9ms\n",
            "Speed: 4.0ms preprocess, 339.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 225.4ms\n",
            "Speed: 4.9ms preprocess, 225.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 carrots, 3 hot dogs, 236.7ms\n",
            "Speed: 3.9ms preprocess, 236.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 hot dog, 245.0ms\n",
            "Speed: 5.3ms preprocess, 245.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cat, 1 dog, 232.0ms\n",
            "Speed: 4.0ms preprocess, 232.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bird, 229.1ms\n",
            "Speed: 4.6ms preprocess, 229.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 238.5ms\n",
            "Speed: 4.1ms preprocess, 238.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 242.7ms\n",
            "Speed: 4.0ms preprocess, 242.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 238.5ms\n",
            "Speed: 4.3ms preprocess, 238.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 232.8ms\n",
            "Speed: 4.3ms preprocess, 232.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 240.7ms\n",
            "Speed: 4.3ms preprocess, 240.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 236.7ms\n",
            "Speed: 5.5ms preprocess, 236.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 sandwich, 1 broccoli, 1 cake, 231.2ms\n",
            "Speed: 4.5ms preprocess, 231.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 220.0ms\n",
            "Speed: 4.2ms preprocess, 220.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 carrots, 244.2ms\n",
            "Speed: 4.6ms preprocess, 244.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 246.8ms\n",
            "Speed: 4.2ms preprocess, 246.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 234.5ms\n",
            "Speed: 4.6ms preprocess, 234.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 keyboard, 229.6ms\n",
            "Speed: 4.7ms preprocess, 229.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 263.8ms\n",
            "Speed: 12.6ms preprocess, 263.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 potted plant, 239.4ms\n",
            "Speed: 3.7ms preprocess, 239.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 229.8ms\n",
            "Speed: 4.1ms preprocess, 229.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 228.6ms\n",
            "Speed: 4.8ms preprocess, 228.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 stop sign, 1 cake, 255.7ms\n",
            "Speed: 4.0ms preprocess, 255.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 1 broccoli, 1 carrot, 228.4ms\n",
            "Speed: 4.4ms preprocess, 228.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 donut, 238.5ms\n",
            "Speed: 6.2ms preprocess, 238.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bottle, 225.9ms\n",
            "Speed: 5.0ms preprocess, 225.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bird, 1 broccoli, 250.3ms\n",
            "Speed: 5.0ms preprocess, 250.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cup, 1 bowl, 2 sandwichs, 1 cake, 236.2ms\n",
            "Speed: 4.5ms preprocess, 236.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 banana, 1 broccoli, 2 donuts, 288.7ms\n",
            "Speed: 7.2ms preprocess, 288.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 225.9ms\n",
            "Speed: 5.3ms preprocess, 225.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cat, 257.7ms\n",
            "Speed: 5.5ms preprocess, 257.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 224.7ms\n",
            "Speed: 3.4ms preprocess, 224.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 228.5ms\n",
            "Speed: 4.6ms preprocess, 228.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 orange, 1 hot dog, 230.7ms\n",
            "Speed: 4.5ms preprocess, 230.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 253.0ms\n",
            "Speed: 4.1ms preprocess, 253.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 1 broccoli, 231.2ms\n",
            "Speed: 5.0ms preprocess, 231.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 237.7ms\n",
            "Speed: 4.5ms preprocess, 237.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 229.9ms\n",
            "Speed: 4.2ms preprocess, 229.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 carrots, 293.1ms\n",
            "Speed: 4.3ms preprocess, 293.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 apple, 242.0ms\n",
            "Speed: 4.9ms preprocess, 242.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kite, 353.4ms\n",
            "Speed: 5.2ms preprocess, 353.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 394.3ms\n",
            "Speed: 4.3ms preprocess, 394.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 1 cake, 352.5ms\n",
            "Speed: 4.3ms preprocess, 352.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 cakes, 354.6ms\n",
            "Speed: 4.2ms preprocess, 354.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 broccoli, 1 carrot, 370.9ms\n",
            "Speed: 4.7ms preprocess, 370.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 364.7ms\n",
            "Speed: 4.3ms preprocess, 364.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 399.2ms\n",
            "Speed: 4.1ms preprocess, 399.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 333.4ms\n",
            "Speed: 4.1ms preprocess, 333.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 255.0ms\n",
            "Speed: 4.3ms preprocess, 255.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 banana, 243.3ms\n",
            "Speed: 5.1ms preprocess, 243.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 238.5ms\n",
            "Speed: 5.8ms preprocess, 238.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bottle, 2 vases, 231.9ms\n",
            "Speed: 4.5ms preprocess, 231.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 cups, 226.9ms\n",
            "Speed: 4.2ms preprocess, 226.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 donut, 240.8ms\n",
            "Speed: 5.6ms preprocess, 240.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bird, 236.2ms\n",
            "Speed: 5.0ms preprocess, 236.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 235.2ms\n",
            "Speed: 5.9ms preprocess, 235.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 hot dog, 235.3ms\n",
            "Speed: 5.4ms preprocess, 235.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 244.6ms\n",
            "Speed: 4.4ms preprocess, 244.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 7 carrots, 249.5ms\n",
            "Speed: 4.2ms preprocess, 249.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 235.5ms\n",
            "Speed: 5.7ms preprocess, 235.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bottle, 235.1ms\n",
            "Speed: 4.0ms preprocess, 235.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 252.4ms\n",
            "Speed: 3.7ms preprocess, 252.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 bananas, 235.8ms\n",
            "Speed: 4.1ms preprocess, 235.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sheep, 241.7ms\n",
            "Speed: 7.2ms preprocess, 241.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 orange, 6 donuts, 238.6ms\n",
            "Speed: 6.7ms preprocess, 238.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 241.5ms\n",
            "Speed: 5.0ms preprocess, 241.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 232.8ms\n",
            "Speed: 4.1ms preprocess, 232.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 241.3ms\n",
            "Speed: 5.0ms preprocess, 241.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 238.3ms\n",
            "Speed: 4.5ms preprocess, 238.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 donuts, 245.1ms\n",
            "Speed: 5.0ms preprocess, 245.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cat, 225.4ms\n",
            "Speed: 5.1ms preprocess, 225.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 238.6ms\n",
            "Speed: 4.8ms preprocess, 238.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 225.8ms\n",
            "Speed: 4.4ms preprocess, 225.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 240.7ms\n",
            "Speed: 6.6ms preprocess, 240.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 237.5ms\n",
            "Speed: 4.3ms preprocess, 237.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 knife, 1 banana, 244.3ms\n",
            "Speed: 4.2ms preprocess, 244.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 8 hot dogs, 231.3ms\n",
            "Speed: 5.0ms preprocess, 231.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 242.3ms\n",
            "Speed: 4.3ms preprocess, 242.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 2 broccolis, 237.9ms\n",
            "Speed: 4.5ms preprocess, 237.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 241.0ms\n",
            "Speed: 5.4ms preprocess, 241.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 carrots, 1 hot dog, 269.1ms\n",
            "Speed: 6.0ms preprocess, 269.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 237.3ms\n",
            "Speed: 5.5ms preprocess, 237.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 fire hydrant, 237.3ms\n",
            "Speed: 4.3ms preprocess, 237.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 235.5ms\n",
            "Speed: 5.1ms preprocess, 235.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 donuts, 245.5ms\n",
            "Speed: 4.8ms preprocess, 245.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 231.8ms\n",
            "Speed: 4.1ms preprocess, 231.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 280.3ms\n",
            "Speed: 4.2ms preprocess, 280.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 369.7ms\n",
            "Speed: 5.2ms preprocess, 369.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 441.5ms\n",
            "Speed: 13.0ms preprocess, 441.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bottle, 3 carrots, 362.0ms\n",
            "Speed: 4.0ms preprocess, 362.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 apples, 5 donuts, 365.1ms\n",
            "Speed: 4.9ms preprocess, 365.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 bowls, 358.8ms\n",
            "Speed: 4.0ms preprocess, 358.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 378.0ms\n",
            "Speed: 5.0ms preprocess, 378.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 396.6ms\n",
            "Speed: 4.3ms preprocess, 396.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 379.2ms\n",
            "Speed: 4.8ms preprocess, 379.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 347.4ms\n",
            "Speed: 4.2ms preprocess, 347.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 235.8ms\n",
            "Speed: 5.7ms preprocess, 235.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 230.5ms\n",
            "Speed: 4.1ms preprocess, 230.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bird, 244.6ms\n",
            "Speed: 6.3ms preprocess, 244.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 teddy bear, 240.4ms\n",
            "Speed: 5.3ms preprocess, 240.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 233.2ms\n",
            "Speed: 4.2ms preprocess, 233.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 carrots, 226.6ms\n",
            "Speed: 4.5ms preprocess, 226.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 2 donuts, 251.2ms\n",
            "Speed: 6.6ms preprocess, 251.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 234.2ms\n",
            "Speed: 4.3ms preprocess, 234.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 oranges, 229.3ms\n",
            "Speed: 4.5ms preprocess, 229.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 224.1ms\n",
            "Speed: 4.6ms preprocess, 224.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 244.3ms\n",
            "Speed: 4.4ms preprocess, 244.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 236.9ms\n",
            "Speed: 5.2ms preprocess, 236.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 246.3ms\n",
            "Speed: 4.4ms preprocess, 246.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 231.0ms\n",
            "Speed: 5.1ms preprocess, 231.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 carrot, 251.2ms\n",
            "Speed: 4.5ms preprocess, 251.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 229.8ms\n",
            "Speed: 6.1ms preprocess, 229.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 227.9ms\n",
            "Speed: 5.1ms preprocess, 227.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 223.2ms\n",
            "Speed: 4.0ms preprocess, 223.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 donuts, 3 teddy bears, 235.3ms\n",
            "Speed: 4.0ms preprocess, 235.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 247.1ms\n",
            "Speed: 4.1ms preprocess, 247.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 234.3ms\n",
            "Speed: 5.2ms preprocess, 234.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 232.1ms\n",
            "Speed: 4.2ms preprocess, 232.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 248.1ms\n",
            "Speed: 5.9ms preprocess, 248.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 236.5ms\n",
            "Speed: 7.5ms preprocess, 236.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 227.5ms\n",
            "Speed: 3.5ms preprocess, 227.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 banana, 226.6ms\n",
            "Speed: 5.4ms preprocess, 226.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 233.0ms\n",
            "Speed: 5.5ms preprocess, 233.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sheeps, 5 donuts, 236.9ms\n",
            "Speed: 4.5ms preprocess, 236.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 bananas, 234.8ms\n",
            "Speed: 4.7ms preprocess, 234.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 228.1ms\n",
            "Speed: 5.1ms preprocess, 228.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 3 bananas, 242.9ms\n",
            "Speed: 3.9ms preprocess, 242.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 237.9ms\n",
            "Speed: 4.1ms preprocess, 237.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 bananas, 235.9ms\n",
            "Speed: 6.9ms preprocess, 235.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 bowls, 3 bananas, 3 broccolis, 236.0ms\n",
            "Speed: 4.2ms preprocess, 236.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 donuts, 246.7ms\n",
            "Speed: 4.4ms preprocess, 246.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 235.3ms\n",
            "Speed: 4.4ms preprocess, 235.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 teddy bear, 233.0ms\n",
            "Speed: 4.2ms preprocess, 233.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 bed, 225.8ms\n",
            "Speed: 4.0ms preprocess, 225.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 carrots, 2 hot dogs, 251.0ms\n",
            "Speed: 4.4ms preprocess, 251.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sports ball, 3 donuts, 330.4ms\n",
            "Speed: 4.6ms preprocess, 330.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 354.3ms\n",
            "Speed: 4.0ms preprocess, 354.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 hot dogs, 362.0ms\n",
            "Speed: 4.0ms preprocess, 362.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 apple, 1 donut, 401.3ms\n",
            "Speed: 4.5ms preprocess, 401.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 348.5ms\n",
            "Speed: 4.0ms preprocess, 348.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 apples, 1 donut, 369.5ms\n",
            "Speed: 4.3ms preprocess, 369.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 361.9ms\n",
            "Speed: 4.6ms preprocess, 361.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 sandwichs, 399.7ms\n",
            "Speed: 4.0ms preprocess, 399.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 oranges, 317.6ms\n",
            "Speed: 4.7ms preprocess, 317.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 228.2ms\n",
            "Speed: 4.6ms preprocess, 228.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 230.5ms\n",
            "Speed: 4.0ms preprocess, 230.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 241.4ms\n",
            "Speed: 4.2ms preprocess, 241.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 246.9ms\n",
            "Speed: 5.1ms preprocess, 246.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 255.7ms\n",
            "Speed: 4.5ms preprocess, 255.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 umbrella, 236.8ms\n",
            "Speed: 4.0ms preprocess, 236.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 236.0ms\n",
            "Speed: 4.1ms preprocess, 236.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 donuts, 245.4ms\n",
            "Speed: 4.4ms preprocess, 245.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 3 carrots, 229.0ms\n",
            "Speed: 4.0ms preprocess, 229.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 carrots, 238.6ms\n",
            "Speed: 4.4ms preprocess, 238.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 orange, 235.1ms\n",
            "Speed: 4.7ms preprocess, 235.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 244.0ms\n",
            "Speed: 4.2ms preprocess, 244.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 229.5ms\n",
            "Speed: 4.1ms preprocess, 229.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 242.2ms\n",
            "Speed: 4.2ms preprocess, 242.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 236.5ms\n",
            "Speed: 4.6ms preprocess, 236.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 3 carrots, 244.1ms\n",
            "Speed: 4.6ms preprocess, 244.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 1 hot dog, 229.5ms\n",
            "Speed: 4.2ms preprocess, 229.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 246.5ms\n",
            "Speed: 4.0ms preprocess, 246.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 229.3ms\n",
            "Speed: 3.9ms preprocess, 229.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 240.9ms\n",
            "Speed: 4.6ms preprocess, 240.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 carrots, 234.4ms\n",
            "Speed: 5.2ms preprocess, 234.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 sandwich, 1 broccoli, 1 donut, 1 cake, 242.9ms\n",
            "Speed: 4.6ms preprocess, 242.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 apples, 1 sandwich, 1 dining table, 229.4ms\n",
            "Speed: 4.6ms preprocess, 229.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 241.1ms\n",
            "Speed: 5.1ms preprocess, 241.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 223.4ms\n",
            "Speed: 6.2ms preprocess, 223.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 apple, 1 orange, 247.3ms\n",
            "Speed: 6.7ms preprocess, 247.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 vase, 234.6ms\n",
            "Speed: 7.6ms preprocess, 234.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 hot dogs, 1 cell phone, 231.2ms\n",
            "Speed: 4.1ms preprocess, 231.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 234.8ms\n",
            "Speed: 4.2ms preprocess, 234.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 cakes, 1 potted plant, 1 dining table, 246.3ms\n",
            "Speed: 4.8ms preprocess, 246.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 224.8ms\n",
            "Speed: 4.0ms preprocess, 224.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 donuts, 230.5ms\n",
            "Speed: 5.4ms preprocess, 230.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 donuts, 234.9ms\n",
            "Speed: 4.1ms preprocess, 234.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 241.5ms\n",
            "Speed: 4.1ms preprocess, 241.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 bananas, 3 donuts, 239.6ms\n",
            "Speed: 8.9ms preprocess, 239.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 5 hot dogs, 229.1ms\n",
            "Speed: 4.7ms preprocess, 229.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 donuts, 253.1ms\n",
            "Speed: 4.9ms preprocess, 253.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 236.3ms\n",
            "Speed: 4.5ms preprocess, 236.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 243.1ms\n",
            "Speed: 4.8ms preprocess, 243.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bird, 1 cake, 376.3ms\n",
            "Speed: 5.4ms preprocess, 376.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 355.4ms\n",
            "Speed: 5.2ms preprocess, 355.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 347.6ms\n",
            "Speed: 4.2ms preprocess, 347.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 1 broccoli, 353.0ms\n",
            "Speed: 4.6ms preprocess, 353.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 4 carrots, 356.2ms\n",
            "Speed: 4.0ms preprocess, 356.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 385.8ms\n",
            "Speed: 4.4ms preprocess, 385.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 bananas, 367.9ms\n",
            "Speed: 4.0ms preprocess, 367.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 383.6ms\n",
            "Speed: 4.0ms preprocess, 383.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 fire hydrant, 1 cake, 381.4ms\n",
            "Speed: 4.2ms preprocess, 381.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 387.0ms\n",
            "Speed: 5.5ms preprocess, 387.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 232.9ms\n",
            "Speed: 4.4ms preprocess, 232.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 2 apples, 1 sandwich, 2 broccolis, 1 carrot, 235.1ms\n",
            "Speed: 4.2ms preprocess, 235.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 banana, 251.8ms\n",
            "Speed: 5.0ms preprocess, 251.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bottle, 225.2ms\n",
            "Speed: 4.9ms preprocess, 225.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 orange, 226.7ms\n",
            "Speed: 5.0ms preprocess, 226.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 orange, 1 broccoli, 260.7ms\n",
            "Speed: 5.5ms preprocess, 260.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 257.8ms\n",
            "Speed: 4.2ms preprocess, 257.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 2 donuts, 225.5ms\n",
            "Speed: 4.5ms preprocess, 225.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 bananas, 1 donut, 237.4ms\n",
            "Speed: 6.7ms preprocess, 237.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 229.6ms\n",
            "Speed: 4.4ms preprocess, 229.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 carrots, 2 hot dogs, 257.3ms\n",
            "Speed: 4.1ms preprocess, 257.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 teddy bear, 233.5ms\n",
            "Speed: 4.4ms preprocess, 233.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 vase, 241.3ms\n",
            "Speed: 5.1ms preprocess, 241.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 zebra, 229.3ms\n",
            "Speed: 4.5ms preprocess, 229.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 257.2ms\n",
            "Speed: 4.9ms preprocess, 257.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.0ms\n",
            "Speed: 8.0ms preprocess, 245.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 carrots, 1 hot dog, 228.4ms\n",
            "Speed: 5.2ms preprocess, 228.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 231.0ms\n",
            "Speed: 5.4ms preprocess, 231.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 256.8ms\n",
            "Speed: 5.4ms preprocess, 256.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 cat, 1 donut, 223.9ms\n",
            "Speed: 5.5ms preprocess, 223.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 233.4ms\n",
            "Speed: 5.1ms preprocess, 233.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 231.1ms\n",
            "Speed: 4.6ms preprocess, 231.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 242.7ms\n",
            "Speed: 4.2ms preprocess, 242.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 dog, 249.2ms\n",
            "Speed: 4.3ms preprocess, 249.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 243.4ms\n",
            "Speed: 4.1ms preprocess, 243.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 242.3ms\n",
            "Speed: 4.3ms preprocess, 242.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 249.9ms\n",
            "Speed: 4.8ms preprocess, 249.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 teddy bear, 244.1ms\n",
            "Speed: 4.1ms preprocess, 244.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 3 bananas, 234.1ms\n",
            "Speed: 4.3ms preprocess, 234.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 235.8ms\n",
            "Speed: 4.1ms preprocess, 235.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 250.5ms\n",
            "Speed: 4.3ms preprocess, 250.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 241.8ms\n",
            "Speed: 4.3ms preprocess, 241.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 donuts, 1 cake, 233.4ms\n",
            "Speed: 4.7ms preprocess, 233.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 cakes, 229.3ms\n",
            "Speed: 4.6ms preprocess, 229.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 donuts, 240.6ms\n",
            "Speed: 7.7ms preprocess, 240.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 260.8ms\n",
            "Speed: 6.2ms preprocess, 260.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 1 hot dog, 239.8ms\n",
            "Speed: 4.2ms preprocess, 239.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 5 hot dogs, 245.7ms\n",
            "Speed: 5.3ms preprocess, 245.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 259.2ms\n",
            "Speed: 4.3ms preprocess, 259.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 carrots, 375.2ms\n",
            "Speed: 4.0ms preprocess, 375.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 370.7ms\n",
            "Speed: 5.4ms preprocess, 370.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 375.9ms\n",
            "Speed: 7.9ms preprocess, 375.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 361.3ms\n",
            "Speed: 5.2ms preprocess, 361.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 sandwichs, 382.1ms\n",
            "Speed: 4.2ms preprocess, 382.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 379.1ms\n",
            "Speed: 4.1ms preprocess, 379.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 661.0ms\n",
            "Speed: 4.3ms preprocess, 661.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 1 carrot, 367.2ms\n",
            "Speed: 4.0ms preprocess, 367.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 235.0ms\n",
            "Speed: 6.2ms preprocess, 235.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 235.5ms\n",
            "Speed: 5.5ms preprocess, 235.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 230.2ms\n",
            "Speed: 6.3ms preprocess, 230.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 dining table, 242.1ms\n",
            "Speed: 6.7ms preprocess, 242.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 5 donuts, 246.8ms\n",
            "Speed: 4.1ms preprocess, 246.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 carrots, 6 hot dogs, 233.3ms\n",
            "Speed: 4.4ms preprocess, 233.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 233.5ms\n",
            "Speed: 4.1ms preprocess, 233.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 dog, 243.0ms\n",
            "Speed: 4.4ms preprocess, 243.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 247.1ms\n",
            "Speed: 4.9ms preprocess, 247.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 233.4ms\n",
            "Speed: 4.4ms preprocess, 233.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 232.7ms\n",
            "Speed: 6.1ms preprocess, 232.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 248.8ms\n",
            "Speed: 4.2ms preprocess, 248.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 bananas, 4 donuts, 246.5ms\n",
            "Speed: 4.3ms preprocess, 246.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 broccolis, 22 carrots, 231.7ms\n",
            "Speed: 4.0ms preprocess, 231.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 2 carrots, 229.2ms\n",
            "Speed: 5.9ms preprocess, 229.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 252.4ms\n",
            "Speed: 4.3ms preprocess, 252.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 245.3ms\n",
            "Speed: 5.0ms preprocess, 245.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 229.4ms\n",
            "Speed: 4.3ms preprocess, 229.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 254.1ms\n",
            "Speed: 6.1ms preprocess, 254.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 249.3ms\n",
            "Speed: 4.8ms preprocess, 249.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 apples, 252.7ms\n",
            "Speed: 5.1ms preprocess, 252.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 vase, 232.2ms\n",
            "Speed: 4.4ms preprocess, 232.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 228.8ms\n",
            "Speed: 4.1ms preprocess, 228.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 253.4ms\n",
            "Speed: 4.0ms preprocess, 253.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 242.9ms\n",
            "Speed: 5.2ms preprocess, 242.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 229.1ms\n",
            "Speed: 4.9ms preprocess, 229.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 hot dogs, 225.9ms\n",
            "Speed: 4.4ms preprocess, 225.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 245.9ms\n",
            "Speed: 4.6ms preprocess, 245.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 256.7ms\n",
            "Speed: 10.7ms preprocess, 256.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 231.2ms\n",
            "Speed: 4.3ms preprocess, 231.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 229.8ms\n",
            "Speed: 3.9ms preprocess, 229.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.4ms\n",
            "Speed: 4.0ms preprocess, 245.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 toothbrush, 241.3ms\n",
            "Speed: 4.2ms preprocess, 241.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 232.8ms\n",
            "Speed: 3.9ms preprocess, 232.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 228.1ms\n",
            "Speed: 4.1ms preprocess, 228.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 fire hydrant, 245.6ms\n",
            "Speed: 4.0ms preprocess, 245.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 orange, 1 broccoli, 1 dining table, 239.0ms\n",
            "Speed: 5.6ms preprocess, 239.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 1 hot dog, 235.3ms\n",
            "Speed: 4.1ms preprocess, 235.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 255.7ms\n",
            "Speed: 5.3ms preprocess, 255.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 bananas, 374.6ms\n",
            "Speed: 4.3ms preprocess, 374.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 carrots, 358.2ms\n",
            "Speed: 4.1ms preprocess, 358.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 sandwich, 1 broccoli, 355.7ms\n",
            "Speed: 4.0ms preprocess, 355.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 373.4ms\n",
            "Speed: 4.0ms preprocess, 373.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 broccoli, 1 carrot, 344.0ms\n",
            "Speed: 4.2ms preprocess, 344.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 2 donuts, 381.3ms\n",
            "Speed: 4.3ms preprocess, 381.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 372.9ms\n",
            "Speed: 4.2ms preprocess, 372.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 386.7ms\n",
            "Speed: 4.9ms preprocess, 386.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 1 broccoli, 1 carrot, 368.0ms\n",
            "Speed: 4.6ms preprocess, 368.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 280.4ms\n",
            "Speed: 9.1ms preprocess, 280.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 230.8ms\n",
            "Speed: 4.3ms preprocess, 230.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 donuts, 243.7ms\n",
            "Speed: 4.6ms preprocess, 243.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 oranges, 271.1ms\n",
            "Speed: 4.1ms preprocess, 271.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 230.0ms\n",
            "Speed: 4.2ms preprocess, 230.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 oranges, 2 broccolis, 242.8ms\n",
            "Speed: 4.2ms preprocess, 242.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 251.5ms\n",
            "Speed: 4.3ms preprocess, 251.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 6 carrots, 3 hot dogs, 245.5ms\n",
            "Speed: 4.4ms preprocess, 245.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 donuts, 235.4ms\n",
            "Speed: 4.1ms preprocess, 235.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 carrots, 239.9ms\n",
            "Speed: 4.2ms preprocess, 239.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 5 carrots, 478.8ms\n",
            "Speed: 4.2ms preprocess, 478.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 237.5ms\n",
            "Speed: 3.9ms preprocess, 237.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 orange, 3 carrots, 240.8ms\n",
            "Speed: 4.0ms preprocess, 240.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 carrots, 239.5ms\n",
            "Speed: 4.5ms preprocess, 239.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 239.9ms\n",
            "Speed: 4.2ms preprocess, 239.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 hot dogs, 231.5ms\n",
            "Speed: 6.2ms preprocess, 231.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 239.4ms\n",
            "Speed: 5.9ms preprocess, 239.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 bananas, 246.0ms\n",
            "Speed: 4.5ms preprocess, 246.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 254.4ms\n",
            "Speed: 4.1ms preprocess, 254.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 5 donuts, 236.6ms\n",
            "Speed: 4.2ms preprocess, 236.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 236.8ms\n",
            "Speed: 11.5ms preprocess, 236.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 2 bananas, 239.5ms\n",
            "Speed: 5.0ms preprocess, 239.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 247.5ms\n",
            "Speed: 4.1ms preprocess, 247.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 231.7ms\n",
            "Speed: 4.4ms preprocess, 231.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 232.0ms\n",
            "Speed: 6.2ms preprocess, 232.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 233.0ms\n",
            "Speed: 5.9ms preprocess, 233.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 239.0ms\n",
            "Speed: 4.2ms preprocess, 239.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 228.6ms\n",
            "Speed: 4.5ms preprocess, 228.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 233.5ms\n",
            "Speed: 4.5ms preprocess, 233.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 246.2ms\n",
            "Speed: 5.0ms preprocess, 246.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 258.4ms\n",
            "Speed: 4.4ms preprocess, 258.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 229.2ms\n",
            "Speed: 4.8ms preprocess, 229.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 2 broccolis, 240.8ms\n",
            "Speed: 6.6ms preprocess, 240.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 donuts, 223.8ms\n",
            "Speed: 4.3ms preprocess, 223.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sheeps, 1 teddy bear, 241.8ms\n",
            "Speed: 4.2ms preprocess, 241.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 231.7ms\n",
            "Speed: 4.1ms preprocess, 231.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 239.3ms\n",
            "Speed: 4.2ms preprocess, 239.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 238.0ms\n",
            "Speed: 4.3ms preprocess, 238.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 dining table, 306.1ms\n",
            "Speed: 5.5ms preprocess, 306.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 352.8ms\n",
            "Speed: 4.5ms preprocess, 352.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 3 donuts, 362.3ms\n",
            "Speed: 5.8ms preprocess, 362.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 broccolis, 365.3ms\n",
            "Speed: 4.1ms preprocess, 365.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 365.1ms\n",
            "Speed: 4.3ms preprocess, 365.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 refrigerator, 354.9ms\n",
            "Speed: 8.9ms preprocess, 354.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 387.7ms\n",
            "Speed: 7.2ms preprocess, 387.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bottle, 2 bananas, 1 donut, 385.7ms\n",
            "Speed: 4.3ms preprocess, 385.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 orange, 1 donut, 395.2ms\n",
            "Speed: 4.3ms preprocess, 395.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 359.9ms\n",
            "Speed: 4.6ms preprocess, 359.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 hot dogs, 233.8ms\n",
            "Speed: 4.1ms preprocess, 233.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 226.3ms\n",
            "Speed: 4.5ms preprocess, 226.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 carrot, 247.2ms\n",
            "Speed: 12.8ms preprocess, 247.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 broccoli, 243.0ms\n",
            "Speed: 4.4ms preprocess, 243.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 228.6ms\n",
            "Speed: 4.0ms preprocess, 228.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 230.2ms\n",
            "Speed: 4.1ms preprocess, 230.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 243.7ms\n",
            "Speed: 4.3ms preprocess, 243.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.0ms\n",
            "Speed: 4.5ms preprocess, 245.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 hot dog, 229.3ms\n",
            "Speed: 4.3ms preprocess, 229.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 hot dogs, 232.9ms\n",
            "Speed: 4.0ms preprocess, 232.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 hot dog, 246.1ms\n",
            "Speed: 4.1ms preprocess, 246.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 1 bowl, 2 donuts, 237.7ms\n",
            "Speed: 4.5ms preprocess, 237.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 258.5ms\n",
            "Speed: 4.0ms preprocess, 258.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 toothbrush, 228.1ms\n",
            "Speed: 4.1ms preprocess, 228.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 247.6ms\n",
            "Speed: 4.2ms preprocess, 247.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 sandwich, 244.5ms\n",
            "Speed: 4.9ms preprocess, 244.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cup, 1 dining table, 230.5ms\n",
            "Speed: 4.1ms preprocess, 230.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 225.8ms\n",
            "Speed: 4.3ms preprocess, 225.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 carrots, 249.2ms\n",
            "Speed: 4.8ms preprocess, 249.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 carrots, 236.8ms\n",
            "Speed: 6.1ms preprocess, 236.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 orange, 228.6ms\n",
            "Speed: 4.7ms preprocess, 228.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 banana, 227.9ms\n",
            "Speed: 4.2ms preprocess, 227.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 263.1ms\n",
            "Speed: 4.8ms preprocess, 263.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 car, 231.9ms\n",
            "Speed: 5.3ms preprocess, 231.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 donut, 233.4ms\n",
            "Speed: 4.5ms preprocess, 233.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 birds, 1 umbrella, 222.5ms\n",
            "Speed: 5.2ms preprocess, 222.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 bowls, 1 sandwich, 1 hot dog, 1 cell phone, 255.0ms\n",
            "Speed: 5.7ms preprocess, 255.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 231.5ms\n",
            "Speed: 4.0ms preprocess, 231.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 sandwichs, 233.3ms\n",
            "Speed: 4.2ms preprocess, 233.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 225.7ms\n",
            "Speed: 4.0ms preprocess, 225.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 250.0ms\n",
            "Speed: 5.4ms preprocess, 250.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 fire hydrant, 2 bananas, 3 donuts, 235.5ms\n",
            "Speed: 4.6ms preprocess, 235.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 vase, 232.8ms\n",
            "Speed: 4.2ms preprocess, 232.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 apple, 1 orange, 225.4ms\n",
            "Speed: 4.1ms preprocess, 225.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 254.9ms\n",
            "Speed: 4.0ms preprocess, 254.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 bananas, 12 donuts, 236.2ms\n",
            "Speed: 3.8ms preprocess, 236.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 26 bananas, 1 pizza, 226.3ms\n",
            "Speed: 4.7ms preprocess, 226.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 228.9ms\n",
            "Speed: 3.9ms preprocess, 228.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.3ms\n",
            "Speed: 4.4ms preprocess, 245.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 4 bananas, 1 dining table, 357.5ms\n",
            "Speed: 4.5ms preprocess, 357.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 banana, 360.4ms\n",
            "Speed: 4.1ms preprocess, 360.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 378.8ms\n",
            "Speed: 4.3ms preprocess, 378.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 347.1ms\n",
            "Speed: 4.1ms preprocess, 347.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 stop sign, 1 donut, 358.7ms\n",
            "Speed: 6.6ms preprocess, 358.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 372.0ms\n",
            "Speed: 5.2ms preprocess, 372.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 355.5ms\n",
            "Speed: 4.6ms preprocess, 355.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 toilet, 388.0ms\n",
            "Speed: 6.0ms preprocess, 388.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 donuts, 398.2ms\n",
            "Speed: 4.5ms preprocess, 398.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 303.3ms\n",
            "Speed: 4.4ms preprocess, 303.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 bananas, 1 cake, 239.5ms\n",
            "Speed: 4.6ms preprocess, 239.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 cakes, 235.7ms\n",
            "Speed: 5.5ms preprocess, 235.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 donuts, 231.4ms\n",
            "Speed: 5.4ms preprocess, 231.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bird, 1 orange, 226.0ms\n",
            "Speed: 4.3ms preprocess, 226.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 243.0ms\n",
            "Speed: 5.2ms preprocess, 243.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 244.8ms\n",
            "Speed: 5.0ms preprocess, 244.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 donut, 226.7ms\n",
            "Speed: 4.1ms preprocess, 226.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 230.9ms\n",
            "Speed: 4.0ms preprocess, 230.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 241.9ms\n",
            "Speed: 3.7ms preprocess, 241.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 carrots, 4 hot dogs, 232.8ms\n",
            "Speed: 7.0ms preprocess, 232.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 233.8ms\n",
            "Speed: 4.9ms preprocess, 233.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bird, 1 broccoli, 228.3ms\n",
            "Speed: 4.1ms preprocess, 228.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 250.3ms\n",
            "Speed: 4.3ms preprocess, 250.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 244.5ms\n",
            "Speed: 4.2ms preprocess, 244.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 246.4ms\n",
            "Speed: 4.9ms preprocess, 246.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 294.0ms\n",
            "Speed: 4.5ms preprocess, 294.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 frisbee, 232.5ms\n",
            "Speed: 5.1ms preprocess, 232.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 242.8ms\n",
            "Speed: 4.4ms preprocess, 242.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 225.1ms\n",
            "Speed: 6.9ms preprocess, 225.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 246.9ms\n",
            "Speed: 6.1ms preprocess, 246.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 broccolis, 240.6ms\n",
            "Speed: 4.2ms preprocess, 240.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 241.9ms\n",
            "Speed: 4.2ms preprocess, 241.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 pizza, 236.9ms\n",
            "Speed: 4.5ms preprocess, 236.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 247.5ms\n",
            "Speed: 4.1ms preprocess, 247.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 240.2ms\n",
            "Speed: 4.2ms preprocess, 240.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 1 broccoli, 246.1ms\n",
            "Speed: 4.5ms preprocess, 246.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 240.0ms\n",
            "Speed: 4.3ms preprocess, 240.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cell phone, 251.5ms\n",
            "Speed: 4.2ms preprocess, 251.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 226.8ms\n",
            "Speed: 7.2ms preprocess, 226.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.6ms\n",
            "Speed: 4.5ms preprocess, 245.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 229.1ms\n",
            "Speed: 4.0ms preprocess, 229.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 252.7ms\n",
            "Speed: 4.3ms preprocess, 252.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 240.3ms\n",
            "Speed: 4.3ms preprocess, 240.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 broccolis, 2 carrots, 240.6ms\n",
            "Speed: 5.2ms preprocess, 240.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 237.1ms\n",
            "Speed: 4.4ms preprocess, 237.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 258.2ms\n",
            "Speed: 4.3ms preprocess, 258.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 broccoli, 235.5ms\n",
            "Speed: 4.5ms preprocess, 235.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 240.8ms\n",
            "Speed: 4.2ms preprocess, 240.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 apples, 1 orange, 1 donut, 343.9ms\n",
            "Speed: 4.3ms preprocess, 343.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 352.5ms\n",
            "Speed: 4.6ms preprocess, 352.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 27 donuts, 370.3ms\n",
            "Speed: 4.1ms preprocess, 370.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 vase, 350.3ms\n",
            "Speed: 4.3ms preprocess, 350.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 broccolis, 6 carrots, 356.6ms\n",
            "Speed: 5.1ms preprocess, 356.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 365.5ms\n",
            "Speed: 4.1ms preprocess, 365.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 donut, 365.5ms\n",
            "Speed: 4.8ms preprocess, 365.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 412.5ms\n",
            "Speed: 6.6ms preprocess, 412.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bench, 1 bottle, 352.8ms\n",
            "Speed: 4.0ms preprocess, 352.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tie, 1 vase, 230.0ms\n",
            "Speed: 5.8ms preprocess, 230.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 229.5ms\n",
            "Speed: 3.9ms preprocess, 229.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 237.0ms\n",
            "Speed: 4.1ms preprocess, 237.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 248.2ms\n",
            "Speed: 5.7ms preprocess, 248.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 toilet, 239.0ms\n",
            "Speed: 4.4ms preprocess, 239.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 fire hydrant, 226.3ms\n",
            "Speed: 4.1ms preprocess, 226.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 232.5ms\n",
            "Speed: 4.2ms preprocess, 232.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 251.8ms\n",
            "Speed: 4.0ms preprocess, 251.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 247.5ms\n",
            "Speed: 10.4ms preprocess, 247.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cat, 1 vase, 232.1ms\n",
            "Speed: 4.2ms preprocess, 232.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 232.9ms\n",
            "Speed: 4.1ms preprocess, 232.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 258.1ms\n",
            "Speed: 5.4ms preprocess, 258.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 236.5ms\n",
            "Speed: 5.6ms preprocess, 236.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 233.6ms\n",
            "Speed: 4.2ms preprocess, 233.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 236.3ms\n",
            "Speed: 4.1ms preprocess, 236.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 1 donut, 270.8ms\n",
            "Speed: 7.0ms preprocess, 270.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 234.4ms\n",
            "Speed: 5.4ms preprocess, 234.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 236.3ms\n",
            "Speed: 4.1ms preprocess, 236.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 cat, 1 banana, 1 carrot, 1 hot dog, 246.5ms\n",
            "Speed: 8.4ms preprocess, 246.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 257.5ms\n",
            "Speed: 4.4ms preprocess, 257.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 3 carrots, 235.3ms\n",
            "Speed: 4.9ms preprocess, 235.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 228.7ms\n",
            "Speed: 5.1ms preprocess, 228.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 hot dog, 241.7ms\n",
            "Speed: 7.3ms preprocess, 241.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 246.9ms\n",
            "Speed: 4.4ms preprocess, 246.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 2 broccolis, 226.9ms\n",
            "Speed: 4.6ms preprocess, 226.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 donut, 234.8ms\n",
            "Speed: 4.5ms preprocess, 234.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 243.3ms\n",
            "Speed: 4.7ms preprocess, 243.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 247.0ms\n",
            "Speed: 4.8ms preprocess, 247.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 234.8ms\n",
            "Speed: 4.4ms preprocess, 234.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 horse, 1 vase, 230.0ms\n",
            "Speed: 4.9ms preprocess, 230.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.6ms\n",
            "Speed: 4.5ms preprocess, 245.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cup, 2 donuts, 249.0ms\n",
            "Speed: 4.5ms preprocess, 249.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 234.6ms\n",
            "Speed: 4.0ms preprocess, 234.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 234.1ms\n",
            "Speed: 4.2ms preprocess, 234.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 bottles, 1 wine glass, 3 cups, 1 bowl, 1 carrot, 1 dining table, 245.4ms\n",
            "Speed: 4.3ms preprocess, 245.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 248.7ms\n",
            "Speed: 4.3ms preprocess, 248.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 carrot, 228.2ms\n",
            "Speed: 4.3ms preprocess, 228.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 238.2ms\n",
            "Speed: 4.1ms preprocess, 238.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 307.9ms\n",
            "Speed: 4.2ms preprocess, 307.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 366.6ms\n",
            "Speed: 4.1ms preprocess, 366.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 351.6ms\n",
            "Speed: 4.1ms preprocess, 351.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 376.3ms\n",
            "Speed: 4.1ms preprocess, 376.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 oranges, 351.8ms\n",
            "Speed: 4.8ms preprocess, 351.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 teddy bear, 361.1ms\n",
            "Speed: 4.2ms preprocess, 361.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 376.3ms\n",
            "Speed: 5.1ms preprocess, 376.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 375.6ms\n",
            "Speed: 9.1ms preprocess, 375.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 386.3ms\n",
            "Speed: 4.0ms preprocess, 386.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 392.8ms\n",
            "Speed: 4.2ms preprocess, 392.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 orange, 2 broccolis, 13 carrots, 277.6ms\n",
            "Speed: 5.4ms preprocess, 277.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 1 apple, 226.6ms\n",
            "Speed: 4.0ms preprocess, 226.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 240.9ms\n",
            "Speed: 4.9ms preprocess, 240.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 broccoli, 1 pizza, 1 dining table, 238.9ms\n",
            "Speed: 4.1ms preprocess, 238.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.7ms\n",
            "Speed: 4.2ms preprocess, 245.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 233.7ms\n",
            "Speed: 4.2ms preprocess, 233.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 241.6ms\n",
            "Speed: 4.0ms preprocess, 241.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 243.7ms\n",
            "Speed: 5.3ms preprocess, 243.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 245.4ms\n",
            "Speed: 6.4ms preprocess, 245.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 233.9ms\n",
            "Speed: 4.2ms preprocess, 233.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 326.0ms\n",
            "Speed: 6.2ms preprocess, 326.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 1 carrot, 233.3ms\n",
            "Speed: 4.2ms preprocess, 233.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 242.6ms\n",
            "Speed: 4.3ms preprocess, 242.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 233.8ms\n",
            "Speed: 6.5ms preprocess, 233.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 236.8ms\n",
            "Speed: 4.1ms preprocess, 236.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 apple, 16 donuts, 233.2ms\n",
            "Speed: 4.0ms preprocess, 233.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 vase, 236.7ms\n",
            "Speed: 4.9ms preprocess, 236.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 236.4ms\n",
            "Speed: 5.5ms preprocess, 236.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 bananas, 242.7ms\n",
            "Speed: 5.2ms preprocess, 242.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 235.2ms\n",
            "Speed: 4.1ms preprocess, 235.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 245.9ms\n",
            "Speed: 9.9ms preprocess, 245.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 231.1ms\n",
            "Speed: 4.0ms preprocess, 231.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 1 book, 308.4ms\n",
            "Speed: 4.7ms preprocess, 308.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 249.9ms\n",
            "Speed: 4.4ms preprocess, 249.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 330.1ms\n",
            "Speed: 7.3ms preprocess, 330.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 265.1ms\n",
            "Speed: 5.0ms preprocess, 265.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 315.3ms\n",
            "Speed: 5.2ms preprocess, 315.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 320.2ms\n",
            "Speed: 5.0ms preprocess, 320.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 269.1ms\n",
            "Speed: 5.5ms preprocess, 269.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 283.3ms\n",
            "Speed: 4.6ms preprocess, 283.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 342.6ms\n",
            "Speed: 5.2ms preprocess, 342.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 239.2ms\n",
            "Speed: 5.9ms preprocess, 239.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 dining table, 241.3ms\n",
            "Speed: 5.0ms preprocess, 241.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 broccolis, 244.7ms\n",
            "Speed: 4.3ms preprocess, 244.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 229.3ms\n",
            "Speed: 4.1ms preprocess, 229.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 carrot, 235.2ms\n",
            "Speed: 4.2ms preprocess, 235.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bottle, 1 vase, 274.3ms\n",
            "Speed: 4.4ms preprocess, 274.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 359.0ms\n",
            "Speed: 4.2ms preprocess, 359.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 carrot, 3 toothbrushs, 380.4ms\n",
            "Speed: 4.3ms preprocess, 380.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 carrots, 371.9ms\n",
            "Speed: 4.2ms preprocess, 371.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 orange, 355.3ms\n",
            "Speed: 4.2ms preprocess, 355.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 2 bananas, 364.3ms\n",
            "Speed: 4.3ms preprocess, 364.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 377.2ms\n",
            "Speed: 6.4ms preprocess, 377.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 sandwich, 375.4ms\n",
            "Speed: 4.1ms preprocess, 375.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 401.6ms\n",
            "Speed: 6.6ms preprocess, 401.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 381.8ms\n",
            "Speed: 6.0ms preprocess, 381.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 toilet, 282.9ms\n",
            "Speed: 4.0ms preprocess, 282.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 237.4ms\n",
            "Speed: 4.1ms preprocess, 237.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 243.3ms\n",
            "Speed: 5.0ms preprocess, 243.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 cake, 237.0ms\n",
            "Speed: 5.0ms preprocess, 237.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 1 broccoli, 225.4ms\n",
            "Speed: 5.5ms preprocess, 225.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 banana, 1 orange, 248.5ms\n",
            "Speed: 4.4ms preprocess, 248.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 donut, 241.2ms\n",
            "Speed: 3.9ms preprocess, 241.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 234.0ms\n",
            "Speed: 4.8ms preprocess, 234.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 bowl, 5 donuts, 229.3ms\n",
            "Speed: 5.3ms preprocess, 229.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tie, 236.5ms\n",
            "Speed: 5.0ms preprocess, 236.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 sandwichs, 1 broccoli, 243.2ms\n",
            "Speed: 5.0ms preprocess, 243.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 donuts, 227.5ms\n",
            "Speed: 4.6ms preprocess, 227.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Augmentation Model**"
      ],
      "metadata": {
        "id": "_TtCC5da-Kuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(0.3),\n",
        "    tf.keras.layers.RandomZoom(0.3),\n",
        "    tf.keras.layers.RandomTranslation(0.3, 0.3),\n",
        "])\n",
        "\n",
        "augmented_train_dataset = training_dataset.map(\n",
        "    lambda x, y: (augmentation_model(x, training=True), y)\n",
        ")"
      ],
      "metadata": {
        "id": "hzccJo8uz5K6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN Model**"
      ],
      "metadata": {
        "id": "nX5aIyjLAAJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\t\ttf.keras.Input(shape=(150,150,3)),\n",
        "        augmentation_model,\n",
        "        tf.keras.layers.Rescaling(1./255),\n",
        "\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        # tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        # tf.keras.layers.BatchNormalization(),\n",
        "        # tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        # tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "        # tf.keras.layers.BatchNormalization(),\n",
        "        # tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "        # tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "        # tf.keras.layers.BatchNormalization(),\n",
        "        # tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(len(training_dataset.class_names), activation='softmax'),\n",
        "    ])\n",
        "\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "7WtO979-_ahg",
        "outputId": "50e41a0f-4cb2-47a0-93a3-dd8f54021997"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_21 (\u001b[38;5;33mSequential\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ rescaling_22 (\u001b[38;5;33mRescaling\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_73 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_73               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_73 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │          \u001b[38;5;34m33,280\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │           \u001b[38;5;34m4,104\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ sequential_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ rescaling_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_73               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,280</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,104</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,432\u001b[0m (154.03 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,432</span> (154.03 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,304\u001b[0m (153.53 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,304</span> (153.53 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Rescaling, BatchNormalization, GlobalAveragePooling2D\n",
        "\n",
        "model = Sequential([\n",
        "    Rescaling(1./255, input_shape=(150, 150, 3)),\n",
        "\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),  # Tambahkan Batch Normalization\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    GlobalAveragePooling2D(),  # Gantikan Flatten dengan Global Average Pooling\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(training_dataset.class_names), activation='softmax')\n",
        "    ])\n",
        "\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=['accuracy']\n",
        "    )"
      ],
      "metadata": {
        "id": "BYRVjJ1Eg3s0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "\ttraining_dataset,\n",
        "\tepochs=100,\n",
        "\tvalidation_data=validation_dataset,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grvCJuZwBgGN",
        "outputId": "b7869454-ee00-4aa5-aac4-a4998ba13eaa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 749ms/step - accuracy: 0.3079 - loss: 2.0436 - val_accuracy: 0.2101 - val_loss: 2.1107\n",
            "Epoch 2/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 761ms/step - accuracy: 0.3983 - loss: 1.5921 - val_accuracy: 0.1812 - val_loss: 2.4832\n",
            "Epoch 3/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 767ms/step - accuracy: 0.4946 - loss: 1.3183 - val_accuracy: 0.2101 - val_loss: 2.6029\n",
            "Epoch 4/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 759ms/step - accuracy: 0.4666 - loss: 1.4595 - val_accuracy: 0.2536 - val_loss: 2.7037\n",
            "Epoch 5/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 749ms/step - accuracy: 0.4767 - loss: 1.4125 - val_accuracy: 0.3261 - val_loss: 1.9325\n",
            "Epoch 6/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 742ms/step - accuracy: 0.5184 - loss: 1.2958 - val_accuracy: 0.2899 - val_loss: 1.9087\n",
            "Epoch 7/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 739ms/step - accuracy: 0.5206 - loss: 1.3386 - val_accuracy: 0.3913 - val_loss: 1.5384\n",
            "Epoch 8/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 737ms/step - accuracy: 0.6044 - loss: 1.1946 - val_accuracy: 0.2464 - val_loss: 2.3245\n",
            "Epoch 9/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 736ms/step - accuracy: 0.5655 - loss: 1.2044 - val_accuracy: 0.5580 - val_loss: 1.1529\n",
            "Epoch 10/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 732ms/step - accuracy: 0.5676 - loss: 1.1332 - val_accuracy: 0.3841 - val_loss: 1.6270\n",
            "Epoch 11/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 707ms/step - accuracy: 0.6162 - loss: 1.0610 - val_accuracy: 0.4493 - val_loss: 1.3335\n",
            "Epoch 12/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 724ms/step - accuracy: 0.5697 - loss: 1.1882 - val_accuracy: 0.4348 - val_loss: 1.9899\n",
            "Epoch 13/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 756ms/step - accuracy: 0.5622 - loss: 1.2506 - val_accuracy: 0.4058 - val_loss: 1.6771\n",
            "Epoch 14/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 723ms/step - accuracy: 0.5732 - loss: 1.1280 - val_accuracy: 0.4058 - val_loss: 1.6962\n",
            "Epoch 15/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 720ms/step - accuracy: 0.6020 - loss: 1.0281 - val_accuracy: 0.5942 - val_loss: 1.1727\n",
            "Epoch 16/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 717ms/step - accuracy: 0.5619 - loss: 1.1134 - val_accuracy: 0.4275 - val_loss: 1.4952\n",
            "Epoch 17/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 715ms/step - accuracy: 0.5861 - loss: 1.0246 - val_accuracy: 0.2101 - val_loss: 6.3918\n",
            "Epoch 18/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 721ms/step - accuracy: 0.5794 - loss: 1.1311 - val_accuracy: 0.3333 - val_loss: 4.7382\n",
            "Epoch 19/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 718ms/step - accuracy: 0.6651 - loss: 0.9689 - val_accuracy: 0.3261 - val_loss: 2.6751\n",
            "Epoch 20/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 744ms/step - accuracy: 0.6811 - loss: 0.9457 - val_accuracy: 0.6014 - val_loss: 1.1723\n",
            "Epoch 21/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 722ms/step - accuracy: 0.6211 - loss: 1.0714 - val_accuracy: 0.4565 - val_loss: 1.3819\n",
            "Epoch 22/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 724ms/step - accuracy: 0.6263 - loss: 0.9298 - val_accuracy: 0.5797 - val_loss: 1.1547\n",
            "Epoch 23/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 718ms/step - accuracy: 0.6730 - loss: 0.8959 - val_accuracy: 0.6812 - val_loss: 0.9733\n",
            "Epoch 24/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 715ms/step - accuracy: 0.7343 - loss: 0.8304 - val_accuracy: 0.4493 - val_loss: 1.6272\n",
            "Epoch 25/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 710ms/step - accuracy: 0.6821 - loss: 0.8452 - val_accuracy: 0.5435 - val_loss: 1.2867\n",
            "Epoch 26/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 715ms/step - accuracy: 0.6827 - loss: 0.8488 - val_accuracy: 0.6232 - val_loss: 1.0648\n",
            "Epoch 27/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 719ms/step - accuracy: 0.6688 - loss: 0.9008 - val_accuracy: 0.5652 - val_loss: 1.6049\n",
            "Epoch 28/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 719ms/step - accuracy: 0.6989 - loss: 0.8735 - val_accuracy: 0.4928 - val_loss: 1.8549\n",
            "Epoch 29/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 725ms/step - accuracy: 0.6527 - loss: 0.8291 - val_accuracy: 0.6377 - val_loss: 1.0839\n",
            "Epoch 30/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 739ms/step - accuracy: 0.6663 - loss: 0.8341 - val_accuracy: 0.5870 - val_loss: 1.2338\n",
            "Epoch 31/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 719ms/step - accuracy: 0.7075 - loss: 0.8264 - val_accuracy: 0.4710 - val_loss: 1.7778\n",
            "Epoch 32/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 714ms/step - accuracy: 0.7729 - loss: 0.7116 - val_accuracy: 0.6594 - val_loss: 0.8888\n",
            "Epoch 33/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 714ms/step - accuracy: 0.7291 - loss: 0.7772 - val_accuracy: 0.5217 - val_loss: 1.2199\n",
            "Epoch 34/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 718ms/step - accuracy: 0.7150 - loss: 0.8210 - val_accuracy: 0.6087 - val_loss: 1.1391\n",
            "Epoch 35/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 717ms/step - accuracy: 0.7520 - loss: 0.6728 - val_accuracy: 0.4130 - val_loss: 2.1153\n",
            "Epoch 36/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 719ms/step - accuracy: 0.7361 - loss: 0.7712 - val_accuracy: 0.6159 - val_loss: 1.1433\n",
            "Epoch 37/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 707ms/step - accuracy: 0.7641 - loss: 0.6799 - val_accuracy: 0.5145 - val_loss: 1.6009\n",
            "Epoch 38/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 687ms/step - accuracy: 0.8059 - loss: 0.5647 - val_accuracy: 0.5507 - val_loss: 1.6213\n",
            "Epoch 39/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 746ms/step - accuracy: 0.7739 - loss: 0.6823 - val_accuracy: 0.6232 - val_loss: 1.2309\n",
            "Epoch 40/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 719ms/step - accuracy: 0.7711 - loss: 0.7155 - val_accuracy: 0.6087 - val_loss: 1.2512\n",
            "Epoch 41/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 719ms/step - accuracy: 0.7855 - loss: 0.5719 - val_accuracy: 0.5725 - val_loss: 1.3757\n",
            "Epoch 42/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 727ms/step - accuracy: 0.7935 - loss: 0.5584 - val_accuracy: 0.5652 - val_loss: 1.3476\n",
            "Epoch 43/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 729ms/step - accuracy: 0.7828 - loss: 0.5293 - val_accuracy: 0.5362 - val_loss: 1.2766\n",
            "Epoch 44/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 728ms/step - accuracy: 0.8451 - loss: 0.4583 - val_accuracy: 0.5072 - val_loss: 1.7581\n",
            "Epoch 45/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 720ms/step - accuracy: 0.7909 - loss: 0.6233 - val_accuracy: 0.6449 - val_loss: 0.9863\n",
            "Epoch 46/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 731ms/step - accuracy: 0.8680 - loss: 0.4560 - val_accuracy: 0.5000 - val_loss: 1.7156\n",
            "Epoch 47/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 723ms/step - accuracy: 0.7894 - loss: 0.5984 - val_accuracy: 0.5652 - val_loss: 1.4910\n",
            "Epoch 48/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 720ms/step - accuracy: 0.8096 - loss: 0.4874 - val_accuracy: 0.5797 - val_loss: 1.4605\n",
            "Epoch 49/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 696ms/step - accuracy: 0.8566 - loss: 0.4045 - val_accuracy: 0.6014 - val_loss: 1.2355\n",
            "Epoch 50/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 709ms/step - accuracy: 0.8536 - loss: 0.4487 - val_accuracy: 0.4203 - val_loss: 2.1989\n",
            "Epoch 51/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 719ms/step - accuracy: 0.8287 - loss: 0.4789 - val_accuracy: 0.6739 - val_loss: 1.0307\n",
            "Epoch 52/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 747ms/step - accuracy: 0.9019 - loss: 0.3242 - val_accuracy: 0.6159 - val_loss: 1.0883\n",
            "Epoch 53/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 727ms/step - accuracy: 0.8740 - loss: 0.3867 - val_accuracy: 0.5290 - val_loss: 1.8726\n",
            "Epoch 54/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 756ms/step - accuracy: 0.8713 - loss: 0.3740 - val_accuracy: 0.6304 - val_loss: 1.3591\n",
            "Epoch 55/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 728ms/step - accuracy: 0.8750 - loss: 0.3711 - val_accuracy: 0.6232 - val_loss: 1.4196\n",
            "Epoch 56/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 766ms/step - accuracy: 0.8645 - loss: 0.4134 - val_accuracy: 0.7174 - val_loss: 1.1120\n",
            "Epoch 57/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 721ms/step - accuracy: 0.8408 - loss: 0.4157 - val_accuracy: 0.4855 - val_loss: 1.5581\n",
            "Epoch 58/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 730ms/step - accuracy: 0.7867 - loss: 0.5275 - val_accuracy: 0.6159 - val_loss: 1.4064\n",
            "Epoch 59/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 727ms/step - accuracy: 0.8553 - loss: 0.3920 - val_accuracy: 0.6087 - val_loss: 1.4410\n",
            "Epoch 60/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 720ms/step - accuracy: 0.8985 - loss: 0.2728 - val_accuracy: 0.5942 - val_loss: 1.6723\n",
            "Epoch 61/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 725ms/step - accuracy: 0.8830 - loss: 0.2984 - val_accuracy: 0.5145 - val_loss: 1.8563\n",
            "Epoch 62/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 726ms/step - accuracy: 0.9303 - loss: 0.2323 - val_accuracy: 0.6232 - val_loss: 1.3908\n",
            "Epoch 63/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 731ms/step - accuracy: 0.9318 - loss: 0.1815 - val_accuracy: 0.6159 - val_loss: 1.4013\n",
            "Epoch 64/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 717ms/step - accuracy: 0.9427 - loss: 0.1991 - val_accuracy: 0.6957 - val_loss: 1.2164\n",
            "Epoch 65/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 750ms/step - accuracy: 0.9385 - loss: 0.1745 - val_accuracy: 0.5580 - val_loss: 1.8809\n",
            "Epoch 66/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 724ms/step - accuracy: 0.9053 - loss: 0.3010 - val_accuracy: 0.5507 - val_loss: 1.7591\n",
            "Epoch 67/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 724ms/step - accuracy: 0.9472 - loss: 0.1520 - val_accuracy: 0.5725 - val_loss: 2.0184\n",
            "Epoch 68/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 723ms/step - accuracy: 0.9135 - loss: 0.2805 - val_accuracy: 0.5072 - val_loss: 2.1404\n",
            "Epoch 69/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 722ms/step - accuracy: 0.8947 - loss: 0.3257 - val_accuracy: 0.6159 - val_loss: 1.6398\n",
            "Epoch 70/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 728ms/step - accuracy: 0.8686 - loss: 0.2813 - val_accuracy: 0.6449 - val_loss: 1.4773\n",
            "Epoch 71/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 727ms/step - accuracy: 0.9326 - loss: 0.1809 - val_accuracy: 0.4420 - val_loss: 3.3095\n",
            "Epoch 72/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 757ms/step - accuracy: 0.9383 - loss: 0.2349 - val_accuracy: 0.6377 - val_loss: 1.7026\n",
            "Epoch 73/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 730ms/step - accuracy: 0.9417 - loss: 0.1460 - val_accuracy: 0.7319 - val_loss: 0.8807\n",
            "Epoch 74/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 730ms/step - accuracy: 0.9272 - loss: 0.1928 - val_accuracy: 0.5362 - val_loss: 3.4627\n",
            "Epoch 75/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 729ms/step - accuracy: 0.9627 - loss: 0.1246 - val_accuracy: 0.6812 - val_loss: 1.2318\n",
            "Epoch 76/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 725ms/step - accuracy: 0.9360 - loss: 0.1893 - val_accuracy: 0.5507 - val_loss: 1.7780\n",
            "Epoch 77/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 729ms/step - accuracy: 0.9327 - loss: 0.2061 - val_accuracy: 0.6449 - val_loss: 1.2838\n",
            "Epoch 78/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 714ms/step - accuracy: 0.9183 - loss: 0.2376 - val_accuracy: 0.6232 - val_loss: 1.5719\n",
            "Epoch 79/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 752ms/step - accuracy: 0.9579 - loss: 0.1514 - val_accuracy: 0.5797 - val_loss: 2.0434\n",
            "Epoch 80/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 723ms/step - accuracy: 0.9651 - loss: 0.1125 - val_accuracy: 0.6522 - val_loss: 1.3465\n",
            "Epoch 81/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 739ms/step - accuracy: 0.9736 - loss: 0.0921 - val_accuracy: 0.6232 - val_loss: 1.5300\n",
            "Epoch 82/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 729ms/step - accuracy: 0.9686 - loss: 0.0977 - val_accuracy: 0.6304 - val_loss: 1.5119\n",
            "Epoch 83/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 732ms/step - accuracy: 0.9836 - loss: 0.0741 - val_accuracy: 0.7029 - val_loss: 1.3603\n",
            "Epoch 84/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 724ms/step - accuracy: 0.9565 - loss: 0.1907 - val_accuracy: 0.6739 - val_loss: 1.4119\n",
            "Epoch 85/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 724ms/step - accuracy: 0.9665 - loss: 0.1022 - val_accuracy: 0.5870 - val_loss: 1.9487\n",
            "Epoch 86/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 729ms/step - accuracy: 0.9336 - loss: 0.1792 - val_accuracy: 0.5797 - val_loss: 2.5572\n",
            "Epoch 87/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 730ms/step - accuracy: 0.9719 - loss: 0.0878 - val_accuracy: 0.6449 - val_loss: 1.6201\n",
            "Epoch 88/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 724ms/step - accuracy: 0.9766 - loss: 0.0797 - val_accuracy: 0.7536 - val_loss: 1.1661\n",
            "Epoch 89/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 760ms/step - accuracy: 0.9731 - loss: 0.0983 - val_accuracy: 0.6159 - val_loss: 1.8316\n",
            "Epoch 90/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 730ms/step - accuracy: 0.9455 - loss: 0.1610 - val_accuracy: 0.4710 - val_loss: 3.0077\n",
            "Epoch 91/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 724ms/step - accuracy: 0.9448 - loss: 0.1639 - val_accuracy: 0.6159 - val_loss: 1.8934\n",
            "Epoch 92/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 723ms/step - accuracy: 0.9545 - loss: 0.1297 - val_accuracy: 0.6812 - val_loss: 1.5675\n",
            "Epoch 93/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 727ms/step - accuracy: 0.9164 - loss: 0.2334 - val_accuracy: 0.6014 - val_loss: 2.0274\n",
            "Epoch 94/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 727ms/step - accuracy: 0.9644 - loss: 0.1422 - val_accuracy: 0.6884 - val_loss: 1.6052\n",
            "Epoch 95/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 746ms/step - accuracy: 0.9914 - loss: 0.0545 - val_accuracy: 0.6377 - val_loss: 1.5114\n",
            "Epoch 96/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 725ms/step - accuracy: 0.9794 - loss: 0.0623 - val_accuracy: 0.6014 - val_loss: 1.9578\n",
            "Epoch 97/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 731ms/step - accuracy: 0.9721 - loss: 0.0882 - val_accuracy: 0.6957 - val_loss: 1.5590\n",
            "Epoch 98/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 719ms/step - accuracy: 0.9700 - loss: 0.1040 - val_accuracy: 0.6522 - val_loss: 1.6538\n",
            "Epoch 99/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 725ms/step - accuracy: 0.9618 - loss: 0.1175 - val_accuracy: 0.7319 - val_loss: 1.0253\n",
            "Epoch 100/100\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 721ms/step - accuracy: 0.9691 - loss: 0.0975 - val_accuracy: 0.6087 - val_loss: 1.8284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get training and validation accuracies\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "fig.suptitle('Training and validation accuracy')\n",
        "\n",
        "for i, (data, label) in enumerate(zip([(acc, val_acc), (loss, val_loss)], [\"Accuracy\", \"Loss\"])):\n",
        "    ax[i].plot(epochs, data[0], 'r', label=\"Training \" + label)\n",
        "    ax[i].plot(epochs, data[1], 'b', label=\"Validation \" + label)\n",
        "    ax[i].legend()\n",
        "    ax[i].set_xlabel('epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "p58EQ6l9DxLb",
        "outputId": "5ad21cd9-4622-4c80-ce18-e86c729dc4cc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}